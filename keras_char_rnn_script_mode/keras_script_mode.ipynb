{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Keras Scripts in SageMaker - Quickstart\n",
    "\n",
    "Starting with TensorFlow version 1.11, you can use SageMaker's TensorFlow containers to train TensorFlow scripts the same way you would train outside SageMaker. This feature is named **Script Mode**. \n",
    "\n",
    "This example is adapted from \n",
    "[Multi-layer Recurrent Neural Networks (LSTM, RNN) for character-level language models in Python using Tensorflow](https://github.com/sherjilozair/char-rnn-tensorflow). \n",
    "You can use the same technique for other scripts or repositories, including \n",
    "[TensorFlow Model Zoo](https://github.com/tensorflow/models) and \n",
    "[TensorFlow benchmark scripts](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks).\n",
    "\n",
    "For this notebook we used the keras version of char-rnn, [char-rnn-keras](https://github.com/ekzhang/char-rnn-keras). We’ll train RNN character-level language models. That is, we’ll give the RNN a huge chunk of text and ask it to model the probability distribution of the next character in the sequence given a sequence of previous characters. This will then allow us to generate new text one character at a time.\n",
    "\n",
    "As a working example, suppose we only had a vocabulary of four possible letters “helo”, and wanted to train an RNN on the training sequence “hello”. This training sequence is in fact a source of 4 separate training examples: 1. The probability of “e” should be likely given the context of “h”, 2. “l” should be likely in the context of “he”, 3. “l” should also be likely given the context of “hel”, and finally 4. “o” should be likely given the context of “hell”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "For training data, we use plain text versions of Sherlock Holmes stories.\n",
    "Let's create a folder named **sherlock** to store our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = os.path.join(os.getcwd(), 'sherlock')\n",
    "\n",
    "os.makedirs(data_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to download the dataset to this folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-08-06 00:41:31--  https://sherlock-holm.es/stories/plain-text/cnus.txt\n",
      "Resolving sherlock-holm.es (sherlock-holm.es)... 78.46.175.31, 2a01:4f8:c0c:1dea::2\n",
      "Connecting to sherlock-holm.es (sherlock-holm.es)|78.46.175.31|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3382026 (3.2M) [text/plain]\n",
      "Saving to: ‘sherlock/input.txt’\n",
      "\n",
      "sherlock/input.txt  100%[===================>]   3.22M  4.28MB/s    in 0.8s    \n",
      "\n",
      "2019-08-06 00:41:32 (4.28 MB/s) - ‘sherlock/input.txt’ saved [3382026/3382026]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://sherlock-holm.es/stories/plain-text/cnus.txt --force-directories --output-document=sherlock/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training script executes in the container as shown bellow:\n",
    "\n",
    "```bash\n",
    "python train.py --epochs 1 --data_dir /opt/ml/input/data/training --model_dir /opt/ml/model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test locally using SageMaker Python SDK TensorFlow Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the SageMaker Python SDK [`TensorFlow`](https://github.com/aws/sagemaker-python-sdk/blob/master/src/sagemaker/tensorflow/README.rst#training-with-tensorflow) estimator to easily train locally and in SageMaker. \n",
    "\n",
    "For this notebook, we will use Keras with the Tensorflow backend\n",
    "\n",
    "Let's start by setting the training script arguments `--epochs` and `--data_dir` as hyperparameters. From the orginal code, the only changes made to allow the script to run natively in SageMaker was converting the data_dir, model_dir, and log_dir variables to arguments that can be passed into the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': 1, 'data_dir': '/opt/ml/input/data/training'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use the SageMaker Python SDK to run your code in a local container before deploying to SageMaker's managed training or hosting environments. Just change your estimator's train_instance_type to local or local_gpu. For more information, see: https://github.com/aws/sagemaker-python-sdk#local-mode.\n",
    "\n",
    "In order to use this feature you'll need to install docker-compose (and nvidia-docker if training with a GPU). Running following script will install docker-compose or nvidia-docker-compose and configure the notebook environment for you.\n",
    "\n",
    "Note, you can only run a single local notebook at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The user has root access.\n",
      "nvidia-docker2 already installed. We are good to go!\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n"
     ]
    }
   ],
   "source": [
    "!/bin/bash ./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train locally, you set `train_instance_type` to [local](https://github.com/aws/sagemaker-python-sdk#local-mode):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_instance_type='local'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the `TensorFlow` Estimator, passing the flag `script_mode=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "\n",
    "estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='char-rnn-keras',\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       train_instance_count=1,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(), # Passes to the container the AWS role that you are using on this notebook\n",
    "                       framework_version='1.13',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start a training job, we call `estimator.fit(inputs)`, where inputs is a dictionary where the keys, named **channels**, \n",
    "have values pointing to the data location. `estimator.fit(inputs)` downloads the TensorFlow container with TensorFlow Python 3, CPU version, locally and simulates a SageMaker training job. \n",
    "When training starts, the TensorFlow container executes **train.py**, passing `hyperparameters` and `model_dir` as script arguments, executing the example as follows:\n",
    "```bash\n",
    "python -m train --num-epochs 1 --data_dir /opt/ml/input/data/training --model_dir /opt/ml/model\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating tmpve_cymz9_algo-1-ntdvh_1 ... \n",
      "\u001b[1BAttaching to tmpve_cymz9_algo-1-ntdvh_12mdone\u001b[0m\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m 2019-08-06 00:52:13,508 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m 2019-08-06 00:52:13,516 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m 2019-08-06 00:52:13,795 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m 2019-08-06 00:52:13,815 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m 2019-08-06 00:52:13,837 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m 2019-08-06 00:52:13,852 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Training Env:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m {\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"current_host\": \"algo-1-ntdvh\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"hosts\": [\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"algo-1-ntdvh\"\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     ],\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"epochs\": 1,\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"data_dir\": \"/opt/ml/input/data/training\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"model_dir\": \"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/model\"\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"training\": {\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         }\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"job_name\": \"tensorflow-training-2019-08-06-00-52-09-482\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"master_hostname\": \"algo-1-ntdvh\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/source/sourcedir.tar.gz\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"module_name\": \"train\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"num_cpus\": 4,\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"current_host\": \"algo-1-ntdvh\",\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         \"hosts\": [\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m             \"algo-1-ntdvh\"\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m         ]\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     },\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m     \"user_entry_point\": \"train.py\"\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m }\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Environment variables:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_HOSTS=[\"algo-1-ntdvh\"]\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_HPS={\"data_dir\":\"/opt/ml/input/data/training\",\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/model\"}\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_USER_ENTRY_POINT=train.py\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-ntdvh\",\"hosts\":[\"algo-1-ntdvh\"]}\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_CURRENT_HOST=algo-1-ntdvh\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_MODULE_NAME=train\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_NUM_CPUS=4\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/source/sourcedir.tar.gz\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-ntdvh\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-ntdvh\"],\"hyperparameters\":{\"data_dir\":\"/opt/ml/input/data/training\",\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2019-08-06-00-52-09-482\",\"log_level\":20,\"master_hostname\":\"algo-1-ntdvh\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-ntdvh\",\"hosts\":[\"algo-1-ntdvh\"]},\"user_entry_point\":\"train.py\"}\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_USER_ARGS=[\"--data_dir\",\"/opt/ml/input/data/training\",\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/model\"]\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_HP_DATA_DIR=/opt/ml/input/data/training\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m SM_HP_MODEL_DIR=s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/model\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m /usr/local/bin/python3.6 train.py --data_dir /opt/ml/input/data/training --epochs 1 --model_dir s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-00-52-09-482/model\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Using TensorFlow backend.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Colocations handled automatically by placer.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Layer (type)                 Output Shape              Param #   \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m embedding_1 (Embedding)      (16, 64, 512)             49664     \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m lstm_1 (LSTM)                (16, 64, 256)             787456    \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m dropout_1 (Dropout)          (16, 64, 256)             0         \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m lstm_2 (LSTM)                (16, 64, 256)             525312    \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m dropout_2 (Dropout)          (16, 64, 256)             0         \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m lstm_3 (LSTM)                (16, 64, 256)             525312    \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m dropout_3 (Dropout)          (16, 64, 256)             0         \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m time_distributed_1 (TimeDist (16, 64, 97)              24929     \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m activation_1 (Activation)    (16, 64, 97)              0         \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m =================================================================\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Total params: 1,912,673\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Trainable params: 1,912,673\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Non-trainable params: 0\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m _________________________________________________________________\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m \n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Epoch 1/1\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Use tf.cast instead.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Instructions for updating:\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Deprecated in favor of operator or tf.math.divide.\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1: loss = 4.5742, acc = 0.01562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 2: loss = 4.5545, acc = 0.26855\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 3: loss = 4.5075, acc = 0.25488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 4: loss = 4.3365, acc = 0.28516\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 5: loss = 3.9202, acc = 0.25195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 6: loss = 3.6771, acc = 0.27148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 7: loss = 3.4232, acc = 0.26465\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 8: loss = 3.2854, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 9: loss = 3.3440, acc = 0.13184\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 10: loss = 3.2701, acc = 0.13672\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 11: loss = 3.2297, acc = 0.19336\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 12: loss = 3.1899, acc = 0.20996\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 13: loss = 3.0772, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 14: loss = 3.0673, acc = 0.25195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 15: loss = 3.0351, acc = 0.25684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 16: loss = 3.0772, acc = 0.24707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 17: loss = 3.0724, acc = 0.24609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 18: loss = 3.0594, acc = 0.23730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 19: loss = 3.0672, acc = 0.25000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 20: loss = 2.9784, acc = 0.25195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 21: loss = 3.0282, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 22: loss = 3.0032, acc = 0.22168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 23: loss = 3.0423, acc = 0.22949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 24: loss = 3.0568, acc = 0.20801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 25: loss = 3.0222, acc = 0.24316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 26: loss = 3.0302, acc = 0.23926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 27: loss = 3.0169, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 28: loss = 3.0094, acc = 0.24121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 29: loss = 3.0652, acc = 0.23730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 30: loss = 3.0034, acc = 0.24805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 31: loss = 2.9608, acc = 0.25000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 32: loss = 3.0323, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 33: loss = 2.9468, acc = 0.26660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 34: loss = 2.9815, acc = 0.24316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 35: loss = 2.9890, acc = 0.24316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 36: loss = 3.0170, acc = 0.24609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 37: loss = 3.0309, acc = 0.23438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 38: loss = 2.9680, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 39: loss = 3.0514, acc = 0.22266\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 40: loss = 3.0539, acc = 0.24805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 41: loss = 2.9617, acc = 0.26270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 42: loss = 3.0062, acc = 0.24512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 43: loss = 2.9928, acc = 0.23340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 44: loss = 3.0514, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 45: loss = 3.0786, acc = 0.24219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 46: loss = 2.9970, acc = 0.24414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 47: loss = 3.0525, acc = 0.23926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 48: loss = 3.0326, acc = 0.24121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 49: loss = 3.0437, acc = 0.24609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 50: loss = 3.0195, acc = 0.24609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 51: loss = 3.0506, acc = 0.25098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 52: loss = 2.9462, acc = 0.25977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 53: loss = 3.0731, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 54: loss = 3.0678, acc = 0.24414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 55: loss = 3.0259, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 56: loss = 3.0255, acc = 0.22949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 57: loss = 3.0030, acc = 0.23926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 58: loss = 3.0405, acc = 0.24023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 59: loss = 2.9962, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 60: loss = 3.0179, acc = 0.22949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 61: loss = 2.9807, acc = 0.23047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 62: loss = 3.0351, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 63: loss = 3.0665, acc = 0.23926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 64: loss = 3.0236, acc = 0.23438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 65: loss = 3.0540, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 66: loss = 2.9843, acc = 0.23633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 67: loss = 2.9739, acc = 0.23730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 68: loss = 2.9927, acc = 0.23047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 69: loss = 3.0725, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 70: loss = 2.9734, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 71: loss = 3.0235, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 72: loss = 2.9911, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 73: loss = 2.9834, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 74: loss = 3.0028, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 75: loss = 2.9432, acc = 0.23438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 76: loss = 2.9757, acc = 0.24023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 77: loss = 3.0345, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 78: loss = 2.9824, acc = 0.24121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 79: loss = 3.0173, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 80: loss = 2.9406, acc = 0.24902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 81: loss = 3.0461, acc = 0.22168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 82: loss = 2.9970, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 83: loss = 2.9985, acc = 0.23926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 84: loss = 2.9449, acc = 0.23828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 85: loss = 2.9602, acc = 0.23633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 86: loss = 3.0469, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 87: loss = 3.0300, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 88: loss = 2.9836, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 89: loss = 3.0335, acc = 0.22266\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 90: loss = 3.0083, acc = 0.23438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 91: loss = 3.0222, acc = 0.22168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 92: loss = 3.0141, acc = 0.22656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 93: loss = 2.9874, acc = 0.23828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 94: loss = 3.0193, acc = 0.23730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 95: loss = 2.9829, acc = 0.22656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 96: loss = 3.0314, acc = 0.22559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 97: loss = 3.0209, acc = 0.23828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 98: loss = 2.9514, acc = 0.22363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 99: loss = 3.0090, acc = 0.22656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 100: loss = 2.9988, acc = 0.24121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 101: loss = 2.9949, acc = 0.22559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 102: loss = 2.9884, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 103: loss = 2.9741, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 104: loss = 2.9987, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 105: loss = 2.9848, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 106: loss = 2.9575, acc = 0.23633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 107: loss = 3.0015, acc = 0.22754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 108: loss = 3.0068, acc = 0.22852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 109: loss = 3.0256, acc = 0.24121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 110: loss = 2.9328, acc = 0.24414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 111: loss = 3.1126, acc = 0.24609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 112: loss = 2.9746, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 113: loss = 3.0084, acc = 0.25195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 114: loss = 2.9975, acc = 0.23926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 115: loss = 3.0597, acc = 0.22949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 116: loss = 3.0368, acc = 0.22266\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 117: loss = 3.0052, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 118: loss = 2.9991, acc = 0.24414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 119: loss = 2.9817, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 120: loss = 3.0385, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 121: loss = 2.9851, acc = 0.23047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 122: loss = 2.9956, acc = 0.23633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 123: loss = 3.0157, acc = 0.23828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 124: loss = 3.0210, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 125: loss = 3.0076, acc = 0.22559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 126: loss = 2.9774, acc = 0.24707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 127: loss = 3.0128, acc = 0.24609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 128: loss = 2.9920, acc = 0.22949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 129: loss = 2.9584, acc = 0.22949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 130: loss = 2.9668, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 131: loss = 2.9917, acc = 0.23145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 132: loss = 3.0059, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 133: loss = 3.0352, acc = 0.22168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 134: loss = 2.9591, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 135: loss = 3.0840, acc = 0.24707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 136: loss = 3.0095, acc = 0.23438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 137: loss = 3.0073, acc = 0.22656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 138: loss = 3.0465, acc = 0.22266\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 139: loss = 2.9856, acc = 0.22559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 140: loss = 2.9464, acc = 0.24023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 141: loss = 2.9592, acc = 0.23438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 142: loss = 2.9658, acc = 0.22070\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 143: loss = 2.9236, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 144: loss = 2.9758, acc = 0.22559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 145: loss = 2.9366, acc = 0.22168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 146: loss = 2.8876, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 147: loss = 2.9341, acc = 0.22461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 148: loss = 2.8926, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 149: loss = 2.8927, acc = 0.23730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 150: loss = 2.8915, acc = 0.22363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 151: loss = 2.9509, acc = 0.23047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 152: loss = 2.8677, acc = 0.24023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 153: loss = 2.8926, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 154: loss = 2.9185, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 155: loss = 2.9558, acc = 0.24707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 156: loss = 2.8855, acc = 0.23047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 157: loss = 2.7863, acc = 0.24219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 158: loss = 2.8377, acc = 0.24707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 159: loss = 2.8444, acc = 0.23535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 160: loss = 2.8136, acc = 0.23242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 161: loss = 2.8602, acc = 0.23633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 162: loss = 2.8506, acc = 0.25293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 163: loss = 2.8446, acc = 0.24414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 164: loss = 2.7892, acc = 0.25391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 165: loss = 2.8189, acc = 0.25586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 166: loss = 2.8058, acc = 0.25781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 167: loss = 2.8087, acc = 0.25391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 168: loss = 2.8003, acc = 0.25195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 169: loss = 2.7691, acc = 0.25098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 170: loss = 2.7400, acc = 0.27246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 171: loss = 2.8800, acc = 0.25488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 172: loss = 2.6657, acc = 0.28027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 173: loss = 2.7162, acc = 0.26074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 174: loss = 2.7740, acc = 0.25195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 175: loss = 2.7553, acc = 0.26172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 176: loss = 2.7131, acc = 0.25098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 177: loss = 2.7323, acc = 0.27539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 178: loss = 2.6946, acc = 0.28125\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 179: loss = 2.6845, acc = 0.28027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 180: loss = 2.7647, acc = 0.25977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 181: loss = 2.7498, acc = 0.26270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 182: loss = 2.7655, acc = 0.26270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 183: loss = 2.6259, acc = 0.27930\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 184: loss = 2.7640, acc = 0.27734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 185: loss = 2.6661, acc = 0.28711\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 186: loss = 2.6264, acc = 0.29199\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 187: loss = 2.6310, acc = 0.29785\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 188: loss = 2.6283, acc = 0.29199\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 189: loss = 2.7200, acc = 0.26562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 190: loss = 2.5985, acc = 0.29297\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 191: loss = 2.6331, acc = 0.28516\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 192: loss = 2.6136, acc = 0.29492\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 193: loss = 2.6268, acc = 0.29297\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 194: loss = 2.5570, acc = 0.30762\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 195: loss = 2.5514, acc = 0.30469\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 196: loss = 2.5639, acc = 0.30078\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 197: loss = 2.5892, acc = 0.29395\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 198: loss = 2.6235, acc = 0.28027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 199: loss = 2.5597, acc = 0.31445\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 200: loss = 2.6680, acc = 0.28125\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 201: loss = 2.5246, acc = 0.30469\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 202: loss = 2.6272, acc = 0.27246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 203: loss = 2.6878, acc = 0.25586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 204: loss = 2.6393, acc = 0.27344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 205: loss = 2.5555, acc = 0.30957\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 206: loss = 2.5879, acc = 0.29883\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 207: loss = 2.6487, acc = 0.28320\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 208: loss = 2.6074, acc = 0.29004\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 209: loss = 2.6020, acc = 0.29980\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 210: loss = 2.6301, acc = 0.28223\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 211: loss = 2.5491, acc = 0.30566\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 212: loss = 2.5628, acc = 0.29688\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 213: loss = 2.6006, acc = 0.28418\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 214: loss = 2.5105, acc = 0.29688\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 215: loss = 2.5659, acc = 0.28906\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 216: loss = 2.5284, acc = 0.30273\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 217: loss = 2.5266, acc = 0.30078\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 218: loss = 2.4649, acc = 0.31836\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 219: loss = 2.5353, acc = 0.31445\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 220: loss = 2.5181, acc = 0.30371\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 221: loss = 2.4780, acc = 0.30371\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 222: loss = 2.5500, acc = 0.29395\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 223: loss = 2.4623, acc = 0.31641\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 224: loss = 2.4662, acc = 0.30078\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 225: loss = 2.5197, acc = 0.30957\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 226: loss = 2.4218, acc = 0.31836\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 227: loss = 2.4544, acc = 0.31641\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 228: loss = 2.4973, acc = 0.32129\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 229: loss = 2.4455, acc = 0.32715\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 230: loss = 2.4800, acc = 0.31250\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 231: loss = 2.4704, acc = 0.31641\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 232: loss = 2.4199, acc = 0.32520\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 233: loss = 2.4079, acc = 0.32422\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 234: loss = 2.4885, acc = 0.32227\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 235: loss = 2.4376, acc = 0.33789\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 236: loss = 2.4947, acc = 0.32812\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 237: loss = 2.4125, acc = 0.32812\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 238: loss = 2.4401, acc = 0.32520\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 239: loss = 2.4179, acc = 0.33984\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 240: loss = 2.4000, acc = 0.34766\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 241: loss = 2.3728, acc = 0.33496\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 242: loss = 2.4539, acc = 0.32324\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 243: loss = 2.3462, acc = 0.35449\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 244: loss = 2.4168, acc = 0.33203\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 245: loss = 2.3512, acc = 0.34180\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 246: loss = 2.4114, acc = 0.32129\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 247: loss = 2.3915, acc = 0.33789\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 248: loss = 2.3557, acc = 0.37207\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 249: loss = 2.3620, acc = 0.35156\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 250: loss = 2.3349, acc = 0.34375\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 251: loss = 2.3461, acc = 0.34863\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 252: loss = 2.3586, acc = 0.34570\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 253: loss = 2.3413, acc = 0.33984\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 254: loss = 2.3693, acc = 0.35156\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 255: loss = 2.3868, acc = 0.35840\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 256: loss = 2.3312, acc = 0.34766\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 257: loss = 2.3523, acc = 0.35352\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 258: loss = 2.4014, acc = 0.34961\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 259: loss = 2.2874, acc = 0.35938\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 260: loss = 2.3410, acc = 0.33789\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 261: loss = 2.3212, acc = 0.34082\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 262: loss = 2.3263, acc = 0.33789\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 263: loss = 2.3268, acc = 0.35645\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 264: loss = 2.3508, acc = 0.33008\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 265: loss = 2.3600, acc = 0.33789\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 266: loss = 2.4374, acc = 0.33008\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 267: loss = 2.2461, acc = 0.37305\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 268: loss = 2.2372, acc = 0.35645\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 269: loss = 2.3572, acc = 0.32422\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 270: loss = 2.3511, acc = 0.34180\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 271: loss = 2.3034, acc = 0.36035\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 272: loss = 2.2893, acc = 0.34863\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 273: loss = 2.2247, acc = 0.36719\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 274: loss = 2.2240, acc = 0.36133\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 275: loss = 2.2594, acc = 0.33984\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 276: loss = 2.2498, acc = 0.35840\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 277: loss = 2.3259, acc = 0.34766\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 278: loss = 2.2774, acc = 0.35742\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 279: loss = 2.3129, acc = 0.34375\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 280: loss = 2.3393, acc = 0.34375\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 281: loss = 2.2876, acc = 0.33203\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 282: loss = 2.2784, acc = 0.34863\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 283: loss = 2.2697, acc = 0.36426\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 284: loss = 2.2439, acc = 0.35352\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 285: loss = 2.3204, acc = 0.33301\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 286: loss = 2.2722, acc = 0.35938\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 287: loss = 2.2178, acc = 0.37012\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 288: loss = 2.2475, acc = 0.36816\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 289: loss = 2.2066, acc = 0.37695\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 290: loss = 2.1545, acc = 0.38281\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 291: loss = 2.2976, acc = 0.34180\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 292: loss = 2.2209, acc = 0.38184\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 293: loss = 2.2082, acc = 0.35254\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 294: loss = 2.2811, acc = 0.35449\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 295: loss = 2.3470, acc = 0.34766\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 296: loss = 2.3005, acc = 0.36719\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 297: loss = 2.1844, acc = 0.39355\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 298: loss = 2.3405, acc = 0.33887\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 299: loss = 2.3005, acc = 0.34961\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 300: loss = 2.2422, acc = 0.35352\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 301: loss = 2.1673, acc = 0.37695\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 302: loss = 2.2842, acc = 0.35840\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 303: loss = 2.2044, acc = 0.35938\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 304: loss = 2.2039, acc = 0.37891\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 305: loss = 2.1906, acc = 0.37500\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 306: loss = 2.2017, acc = 0.36426\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 307: loss = 2.2240, acc = 0.37207\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 308: loss = 2.2433, acc = 0.37207\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 309: loss = 2.2127, acc = 0.37598\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 310: loss = 2.2785, acc = 0.34863\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 311: loss = 2.2267, acc = 0.37891\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 312: loss = 2.2086, acc = 0.35352\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 313: loss = 2.1829, acc = 0.38086\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 314: loss = 2.2518, acc = 0.36230\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 315: loss = 2.3488, acc = 0.35742\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 316: loss = 2.2208, acc = 0.36230\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 317: loss = 2.2276, acc = 0.37500\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 318: loss = 2.2103, acc = 0.36328\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 319: loss = 2.1173, acc = 0.39746\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 320: loss = 2.2361, acc = 0.37109\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 321: loss = 2.3942, acc = 0.36133\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 322: loss = 2.2386, acc = 0.39551\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 323: loss = 2.2268, acc = 0.36621\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 324: loss = 2.2330, acc = 0.37402\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 325: loss = 2.1714, acc = 0.37402\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 326: loss = 2.2751, acc = 0.34082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 327: loss = 2.2384, acc = 0.37695\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 328: loss = 2.2480, acc = 0.34766\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 329: loss = 2.1969, acc = 0.36133\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 330: loss = 2.1623, acc = 0.36426\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 331: loss = 2.2602, acc = 0.35156\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 332: loss = 2.2320, acc = 0.34863\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 333: loss = 2.1872, acc = 0.36523\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 334: loss = 2.2266, acc = 0.36230\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 335: loss = 2.1811, acc = 0.35742\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 336: loss = 2.2507, acc = 0.36230\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 337: loss = 2.4575, acc = 0.35840\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 338: loss = 2.2330, acc = 0.36133\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 339: loss = 2.2271, acc = 0.37500\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 340: loss = 2.2896, acc = 0.36816\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 341: loss = 2.2304, acc = 0.35547\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 342: loss = 2.3026, acc = 0.36133\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 343: loss = 2.2187, acc = 0.36914\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 344: loss = 2.2315, acc = 0.36621\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 345: loss = 2.1176, acc = 0.40527\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 346: loss = 2.1381, acc = 0.40137\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 347: loss = 2.1772, acc = 0.38184\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 348: loss = 2.3390, acc = 0.38867\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 349: loss = 2.2246, acc = 0.35645\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 350: loss = 2.1939, acc = 0.34668\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 351: loss = 2.1559, acc = 0.37988\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 352: loss = 2.1147, acc = 0.40039\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 353: loss = 2.1291, acc = 0.39160\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 354: loss = 2.1446, acc = 0.37598\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 355: loss = 2.2358, acc = 0.34082\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 356: loss = 2.1285, acc = 0.38965\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 357: loss = 2.0613, acc = 0.40332\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 358: loss = 2.2003, acc = 0.38086\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 359: loss = 2.1447, acc = 0.38281\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 360: loss = 2.1527, acc = 0.37012\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 361: loss = 2.1840, acc = 0.37695\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 362: loss = 2.0475, acc = 0.41113\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 363: loss = 2.0513, acc = 0.40234\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 364: loss = 2.1740, acc = 0.37598\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 365: loss = 2.1085, acc = 0.39941\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 366: loss = 2.1151, acc = 0.39746\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 367: loss = 2.1286, acc = 0.38965\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 368: loss = 2.1390, acc = 0.37598\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 369: loss = 2.2330, acc = 0.35352\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 370: loss = 2.1089, acc = 0.39160\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 371: loss = 2.0265, acc = 0.42285\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 372: loss = 2.1596, acc = 0.38672\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 373: loss = 2.0515, acc = 0.41211\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 374: loss = 2.1753, acc = 0.36523\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 375: loss = 2.1651, acc = 0.37891\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 376: loss = 2.1731, acc = 0.38379\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 377: loss = 2.1903, acc = 0.37305\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 378: loss = 2.1126, acc = 0.40039\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 379: loss = 2.1483, acc = 0.39746\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 380: loss = 2.1735, acc = 0.36914\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 381: loss = 2.1653, acc = 0.37500\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 382: loss = 2.1387, acc = 0.39844\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 383: loss = 2.1413, acc = 0.38086\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 384: loss = 2.1506, acc = 0.38477\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 385: loss = 2.1904, acc = 0.38379\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 386: loss = 2.2245, acc = 0.39551\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 387: loss = 2.1061, acc = 0.40137\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 388: loss = 2.0658, acc = 0.39453\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 389: loss = 2.0721, acc = 0.41309\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 390: loss = 2.1808, acc = 0.38086\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 391: loss = 2.0793, acc = 0.41504\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 392: loss = 2.1193, acc = 0.39062\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 393: loss = 2.1226, acc = 0.40625\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 394: loss = 2.1046, acc = 0.40234\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 395: loss = 2.0463, acc = 0.40039\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 396: loss = 2.0437, acc = 0.39941\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 397: loss = 2.0783, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 398: loss = 2.1013, acc = 0.39453\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 399: loss = 2.1525, acc = 0.38184\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 400: loss = 2.1372, acc = 0.39062\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 401: loss = 2.0961, acc = 0.39551\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 402: loss = 2.1219, acc = 0.38379\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 403: loss = 2.0971, acc = 0.39258\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 404: loss = 2.0704, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 405: loss = 2.0816, acc = 0.40137\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 406: loss = 2.0531, acc = 0.40918\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 407: loss = 2.0936, acc = 0.38965\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 408: loss = 2.0898, acc = 0.39844\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 409: loss = 2.1310, acc = 0.39746\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 410: loss = 2.0903, acc = 0.40820\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 411: loss = 2.0733, acc = 0.39355\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 412: loss = 2.1398, acc = 0.41797\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 413: loss = 2.2002, acc = 0.38477\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 414: loss = 2.0790, acc = 0.38379\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 415: loss = 2.1211, acc = 0.38184\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 416: loss = 2.0400, acc = 0.40039\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 417: loss = 2.0511, acc = 0.40723\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 418: loss = 2.1227, acc = 0.40039\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 419: loss = 2.0896, acc = 0.38965\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 420: loss = 2.1221, acc = 0.37891\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 421: loss = 2.1155, acc = 0.38770\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 422: loss = 2.0695, acc = 0.42383\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 423: loss = 2.0399, acc = 0.40527\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 424: loss = 2.1672, acc = 0.37500\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 425: loss = 1.9601, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 426: loss = 2.1286, acc = 0.38574\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 427: loss = 2.0731, acc = 0.41113\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 428: loss = 2.1623, acc = 0.39258\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 429: loss = 2.1012, acc = 0.39355\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 430: loss = 2.0260, acc = 0.39844\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 431: loss = 2.1319, acc = 0.37109\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 432: loss = 2.0673, acc = 0.39551\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 433: loss = 2.0383, acc = 0.41699\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 434: loss = 2.0574, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 435: loss = 2.1514, acc = 0.38574\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 436: loss = 2.1187, acc = 0.38867\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 437: loss = 2.0183, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 438: loss = 2.0141, acc = 0.40820\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 439: loss = 2.1466, acc = 0.36816\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 440: loss = 2.0954, acc = 0.39355\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 441: loss = 2.0637, acc = 0.41699\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 442: loss = 2.0899, acc = 0.39453\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 443: loss = 2.1131, acc = 0.39062\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 444: loss = 2.0507, acc = 0.41797\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 445: loss = 2.0197, acc = 0.42871\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 446: loss = 1.9490, acc = 0.43262\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 447: loss = 2.0052, acc = 0.40430\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 448: loss = 2.0667, acc = 0.40918\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 449: loss = 2.0078, acc = 0.41406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 450: loss = 2.0345, acc = 0.40820\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 451: loss = 2.0849, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 452: loss = 2.1143, acc = 0.38672\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 453: loss = 2.0777, acc = 0.43848\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 454: loss = 2.0156, acc = 0.42676\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 455: loss = 2.0854, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 456: loss = 2.0443, acc = 0.42188\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 457: loss = 2.0030, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 458: loss = 1.9636, acc = 0.43555\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 459: loss = 1.9582, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 460: loss = 2.0705, acc = 0.41406\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 461: loss = 1.9716, acc = 0.42090\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 462: loss = 1.9016, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 463: loss = 1.9884, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 464: loss = 2.0433, acc = 0.40332\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 465: loss = 2.0125, acc = 0.40430\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 466: loss = 1.9778, acc = 0.42773\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 467: loss = 2.0616, acc = 0.39551\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 468: loss = 2.0296, acc = 0.41113\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 469: loss = 2.0395, acc = 0.38770\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 470: loss = 1.9710, acc = 0.42285\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 471: loss = 2.0025, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 472: loss = 1.9499, acc = 0.44336\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 473: loss = 2.0062, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 474: loss = 2.0164, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 475: loss = 1.9060, acc = 0.42383\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 476: loss = 2.0674, acc = 0.41406\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 477: loss = 1.9705, acc = 0.43262\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 478: loss = 2.0067, acc = 0.40723\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 479: loss = 2.0389, acc = 0.42383\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 480: loss = 1.9007, acc = 0.43750\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 481: loss = 1.9971, acc = 0.40820\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 482: loss = 1.9950, acc = 0.41113\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 483: loss = 1.9924, acc = 0.43066\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 484: loss = 2.0341, acc = 0.40137\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 485: loss = 1.9863, acc = 0.42285\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 486: loss = 1.9336, acc = 0.44141\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 487: loss = 2.0952, acc = 0.40332\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 488: loss = 1.9282, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 489: loss = 1.9636, acc = 0.42480\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 490: loss = 1.9284, acc = 0.43262\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 491: loss = 1.9288, acc = 0.43848\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 492: loss = 1.9838, acc = 0.41211\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 493: loss = 1.9917, acc = 0.43457\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 494: loss = 1.9340, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 495: loss = 1.9569, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 496: loss = 1.9498, acc = 0.42676\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 497: loss = 2.0143, acc = 0.39453\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 498: loss = 1.9083, acc = 0.43457\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 499: loss = 1.9296, acc = 0.41016\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 500: loss = 1.8946, acc = 0.44531\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 501: loss = 1.9838, acc = 0.40625\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 502: loss = 1.9398, acc = 0.44043\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 503: loss = 2.0030, acc = 0.41504\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 504: loss = 1.9207, acc = 0.42383\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 505: loss = 2.0042, acc = 0.41797\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 506: loss = 1.8974, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 507: loss = 1.9941, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 508: loss = 1.9617, acc = 0.42871\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 509: loss = 1.9675, acc = 0.42676\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 510: loss = 1.9440, acc = 0.44629\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 511: loss = 1.9092, acc = 0.43750\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 512: loss = 2.0026, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 513: loss = 1.9841, acc = 0.42578\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 514: loss = 1.9594, acc = 0.43457\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 515: loss = 2.0431, acc = 0.39453\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 516: loss = 1.9507, acc = 0.43750\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 517: loss = 1.9367, acc = 0.43652\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 518: loss = 1.9783, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 519: loss = 1.9418, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 520: loss = 1.9456, acc = 0.44531\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 521: loss = 2.0174, acc = 0.40918\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 522: loss = 1.9385, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 523: loss = 1.9875, acc = 0.42285\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 524: loss = 1.9625, acc = 0.42773\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 525: loss = 1.9142, acc = 0.42480\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 526: loss = 1.9013, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 527: loss = 1.9080, acc = 0.44043\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 528: loss = 1.8975, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 529: loss = 1.8997, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 530: loss = 1.9271, acc = 0.44629\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 531: loss = 1.9872, acc = 0.42480\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 532: loss = 1.8939, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 533: loss = 1.9079, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 534: loss = 1.8995, acc = 0.43457\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 535: loss = 1.9720, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 536: loss = 1.9345, acc = 0.42676\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 537: loss = 1.8762, acc = 0.43945\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 538: loss = 2.0097, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 539: loss = 1.9268, acc = 0.43066\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 540: loss = 1.9272, acc = 0.42578\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 541: loss = 1.9327, acc = 0.44043\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 542: loss = 1.9550, acc = 0.42480\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 543: loss = 1.9244, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 544: loss = 1.9346, acc = 0.42188\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 545: loss = 1.8692, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 546: loss = 1.8686, acc = 0.43066\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 547: loss = 2.0503, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 548: loss = 1.9881, acc = 0.44141\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 549: loss = 1.8965, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 550: loss = 1.8976, acc = 0.44629\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 551: loss = 1.9049, acc = 0.44531\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 552: loss = 1.8461, acc = 0.44238\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 553: loss = 1.9076, acc = 0.42676\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 554: loss = 1.9093, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 555: loss = 1.9531, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 556: loss = 1.9528, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 557: loss = 1.8573, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 558: loss = 1.8249, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 559: loss = 1.9552, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 560: loss = 1.8515, acc = 0.43457\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 561: loss = 1.9839, acc = 0.41602\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 562: loss = 1.9516, acc = 0.43066\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 563: loss = 1.8742, acc = 0.44824\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 564: loss = 1.8494, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 565: loss = 1.9736, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 566: loss = 1.9548, acc = 0.42188\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 567: loss = 1.8428, acc = 0.44043\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 568: loss = 1.9427, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 569: loss = 1.9573, acc = 0.42188\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 570: loss = 1.9207, acc = 0.43555\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 571: loss = 1.9171, acc = 0.42383\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 572: loss = 1.8538, acc = 0.44629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 573: loss = 1.8678, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 574: loss = 1.9523, acc = 0.43555\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 575: loss = 1.8100, acc = 0.46289\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 576: loss = 1.9449, acc = 0.40723\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 577: loss = 1.8800, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 578: loss = 1.8986, acc = 0.44238\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 579: loss = 1.8648, acc = 0.45508\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 580: loss = 1.9098, acc = 0.43945\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 581: loss = 1.9233, acc = 0.43848\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 582: loss = 1.9592, acc = 0.42676\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 583: loss = 1.8525, acc = 0.42871\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 584: loss = 1.8345, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 585: loss = 1.9353, acc = 0.44336\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 586: loss = 1.9282, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 587: loss = 1.8138, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 588: loss = 1.8059, acc = 0.47363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 589: loss = 2.0623, acc = 0.41309\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 590: loss = 1.9407, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 591: loss = 1.9230, acc = 0.43652\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 592: loss = 1.9192, acc = 0.42871\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 593: loss = 1.9252, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 594: loss = 2.0459, acc = 0.43066\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 595: loss = 1.8188, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 596: loss = 1.8411, acc = 0.44727\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 597: loss = 1.8769, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 598: loss = 1.9068, acc = 0.44336\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 599: loss = 1.8722, acc = 0.44238\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 600: loss = 1.8180, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 601: loss = 1.9714, acc = 0.41992\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 602: loss = 1.8842, acc = 0.44824\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 603: loss = 1.9431, acc = 0.41113\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 604: loss = 1.8897, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 605: loss = 1.9385, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 606: loss = 2.0879, acc = 0.41504\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 607: loss = 1.9237, acc = 0.44531\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 608: loss = 1.9380, acc = 0.40918\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 609: loss = 1.8497, acc = 0.45508\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 610: loss = 1.8773, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 611: loss = 1.9805, acc = 0.41895\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 612: loss = 1.8897, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 613: loss = 1.8678, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 614: loss = 1.9726, acc = 0.44141\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 615: loss = 2.0334, acc = 0.41699\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 616: loss = 1.9895, acc = 0.41699\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 617: loss = 1.8749, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 618: loss = 1.9712, acc = 0.42578\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 619: loss = 1.9581, acc = 0.42285\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 620: loss = 1.9183, acc = 0.43262\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 621: loss = 1.8834, acc = 0.45020\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 622: loss = 1.9124, acc = 0.43262\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 623: loss = 1.8723, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 624: loss = 1.9014, acc = 0.44141\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 625: loss = 1.9050, acc = 0.43359\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 626: loss = 1.9521, acc = 0.43262\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 627: loss = 1.8952, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 628: loss = 1.9678, acc = 0.43750\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 629: loss = 1.9093, acc = 0.45410\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 630: loss = 1.7884, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 631: loss = 1.8412, acc = 0.43945\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 632: loss = 1.8175, acc = 0.46582\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 633: loss = 1.8012, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 634: loss = 1.8197, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 635: loss = 1.8971, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 636: loss = 1.8735, acc = 0.45508\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 637: loss = 1.8409, acc = 0.43652\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 638: loss = 1.8367, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 639: loss = 1.8686, acc = 0.44824\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 640: loss = 1.8199, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 641: loss = 1.8247, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 642: loss = 1.7526, acc = 0.46289\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 643: loss = 1.8755, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 644: loss = 1.8522, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 645: loss = 1.8601, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 646: loss = 1.9146, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 647: loss = 1.8235, acc = 0.46191\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 648: loss = 1.8354, acc = 0.47266\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 649: loss = 1.8277, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 650: loss = 1.8854, acc = 0.44629\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 651: loss = 1.9750, acc = 0.43750\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 652: loss = 1.8484, acc = 0.45996\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 653: loss = 1.8803, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 654: loss = 1.8553, acc = 0.44629\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 655: loss = 1.8300, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 656: loss = 1.8359, acc = 0.44238\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 657: loss = 1.9048, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 658: loss = 1.8785, acc = 0.45410\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 659: loss = 1.7623, acc = 0.47949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 660: loss = 1.8655, acc = 0.44141\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 661: loss = 1.8408, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 662: loss = 1.8193, acc = 0.44727\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 663: loss = 1.8164, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 664: loss = 1.8390, acc = 0.45605\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 665: loss = 1.8573, acc = 0.44141\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 666: loss = 1.7786, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 667: loss = 1.7676, acc = 0.47559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 668: loss = 1.8122, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 669: loss = 1.8591, acc = 0.46484\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 670: loss = 1.8445, acc = 0.43750\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 671: loss = 1.8672, acc = 0.44531\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 672: loss = 1.7962, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 673: loss = 1.8708, acc = 0.45410\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 674: loss = 1.8716, acc = 0.42969\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 675: loss = 1.8593, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 676: loss = 1.8486, acc = 0.45020\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 677: loss = 1.8347, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 678: loss = 1.7873, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 679: loss = 1.8260, acc = 0.45410\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 680: loss = 1.8646, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 681: loss = 1.8374, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 682: loss = 1.7806, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 683: loss = 1.7931, acc = 0.47559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 684: loss = 1.8734, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 685: loss = 1.8217, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 686: loss = 1.7836, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 687: loss = 1.8731, acc = 0.46484\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 688: loss = 1.7330, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 689: loss = 1.8536, acc = 0.46191\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 690: loss = 1.8397, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 691: loss = 1.7936, acc = 0.45605\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 692: loss = 1.8410, acc = 0.45605\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 693: loss = 1.8404, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 694: loss = 1.8433, acc = 0.46289\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 695: loss = 1.8878, acc = 0.44434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 696: loss = 1.9508, acc = 0.47559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 697: loss = 1.7494, acc = 0.47363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 698: loss = 1.8118, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 699: loss = 1.8047, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 700: loss = 1.7614, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 701: loss = 1.8407, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 702: loss = 1.8838, acc = 0.43652\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 703: loss = 1.8103, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 704: loss = 1.8396, acc = 0.46582\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 705: loss = 1.7752, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 706: loss = 1.8081, acc = 0.45996\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 707: loss = 1.7903, acc = 0.47266\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 708: loss = 1.8136, acc = 0.46387\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 709: loss = 1.8803, acc = 0.43555\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 710: loss = 1.8016, acc = 0.48535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 711: loss = 1.7604, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 712: loss = 1.8421, acc = 0.45508\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 713: loss = 1.8269, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 714: loss = 1.8584, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 715: loss = 1.8203, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 716: loss = 1.8300, acc = 0.46289\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 717: loss = 1.7038, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 718: loss = 1.7668, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 719: loss = 1.7786, acc = 0.47461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 720: loss = 1.7677, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 721: loss = 1.8040, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 722: loss = 1.7205, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 723: loss = 1.6850, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 724: loss = 1.8501, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 725: loss = 1.7625, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 726: loss = 1.7832, acc = 0.46289\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 727: loss = 1.7849, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 728: loss = 1.8173, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 729: loss = 1.6783, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 730: loss = 1.7615, acc = 0.45996\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 731: loss = 1.7816, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 732: loss = 1.7782, acc = 0.47559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 733: loss = 1.7756, acc = 0.47363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 734: loss = 1.8029, acc = 0.47363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 735: loss = 1.8619, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 736: loss = 1.8793, acc = 0.44824\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 737: loss = 1.7940, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 738: loss = 1.7693, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 739: loss = 1.8392, acc = 0.44434\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 740: loss = 1.8716, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 741: loss = 1.8408, acc = 0.45117\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 742: loss = 1.8182, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 743: loss = 1.7539, acc = 0.50000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 744: loss = 1.8130, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 745: loss = 1.9316, acc = 0.43848\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 746: loss = 1.8836, acc = 0.45020\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 747: loss = 1.9223, acc = 0.44531\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 748: loss = 1.8684, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 749: loss = 1.8129, acc = 0.47461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 750: loss = 2.0010, acc = 0.42285\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 751: loss = 1.8801, acc = 0.45605\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 752: loss = 1.7859, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 753: loss = 1.7062, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 754: loss = 1.7580, acc = 0.48340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 755: loss = 2.0114, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 756: loss = 1.7392, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 757: loss = 1.7449, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 758: loss = 1.8465, acc = 0.44922\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 759: loss = 1.7702, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 760: loss = 1.8297, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 761: loss = 1.7683, acc = 0.46582\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 762: loss = 1.7839, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 763: loss = 1.8619, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 764: loss = 1.8144, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 765: loss = 1.8137, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 766: loss = 1.8156, acc = 0.47070\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 767: loss = 1.7361, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 768: loss = 1.9031, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 769: loss = 1.7824, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 770: loss = 1.7783, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 771: loss = 1.6500, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 772: loss = 1.7083, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 773: loss = 1.7913, acc = 0.47754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 774: loss = 1.7561, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 775: loss = 1.8062, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 776: loss = 1.8357, acc = 0.46875\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 777: loss = 1.8086, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 778: loss = 1.7648, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 779: loss = 1.8285, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 780: loss = 1.7652, acc = 0.47461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 781: loss = 1.7758, acc = 0.47070\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 782: loss = 1.7868, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 783: loss = 1.7172, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 784: loss = 1.7164, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 785: loss = 1.7579, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 786: loss = 1.8555, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 787: loss = 1.7600, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 788: loss = 1.7552, acc = 0.47949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 789: loss = 1.8206, acc = 0.48047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 790: loss = 1.8633, acc = 0.45312\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 791: loss = 1.8861, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 792: loss = 1.9656, acc = 0.44727\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 793: loss = 1.8897, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 794: loss = 1.7990, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 795: loss = 1.8823, acc = 0.45410\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 796: loss = 1.7559, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 797: loss = 1.7717, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 798: loss = 1.7614, acc = 0.47070\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 799: loss = 1.7495, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 800: loss = 1.7833, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 801: loss = 1.7765, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 802: loss = 1.7511, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 803: loss = 1.7616, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 804: loss = 1.7438, acc = 0.46484\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 805: loss = 1.8196, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 806: loss = 1.8047, acc = 0.45605\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 807: loss = 1.7527, acc = 0.49707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 808: loss = 1.6366, acc = 0.51953\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 809: loss = 1.7687, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 810: loss = 1.7355, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 811: loss = 1.7344, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 812: loss = 1.7935, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 813: loss = 1.7436, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 814: loss = 1.6695, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 815: loss = 1.6798, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 816: loss = 1.6540, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 817: loss = 1.7848, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 818: loss = 1.6811, acc = 0.50195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 819: loss = 1.6922, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 820: loss = 1.6820, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 821: loss = 1.6839, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 822: loss = 1.7368, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 823: loss = 1.6642, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 824: loss = 1.8472, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 825: loss = 1.7225, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 826: loss = 1.6646, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 827: loss = 1.7426, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 828: loss = 1.7278, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 829: loss = 1.7828, acc = 0.47070\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 830: loss = 1.7569, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 831: loss = 1.8359, acc = 0.46094\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 832: loss = 1.6896, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 833: loss = 1.7111, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 834: loss = 1.6145, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 835: loss = 1.6758, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 836: loss = 1.7819, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 837: loss = 1.7982, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 838: loss = 1.8489, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 839: loss = 1.8216, acc = 0.45508\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 840: loss = 1.6932, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 841: loss = 1.6625, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 842: loss = 1.7506, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 843: loss = 1.7428, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 844: loss = 1.7034, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 845: loss = 1.8286, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 846: loss = 1.7076, acc = 0.50000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 847: loss = 1.7199, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 848: loss = 1.7168, acc = 0.46387\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 849: loss = 1.7923, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 850: loss = 1.7253, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 851: loss = 1.6941, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 852: loss = 1.7837, acc = 0.45215\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 853: loss = 1.9729, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 854: loss = 1.7400, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 855: loss = 1.7149, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 856: loss = 1.7455, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 857: loss = 1.8060, acc = 0.45898\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 858: loss = 1.7186, acc = 0.50000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 859: loss = 1.6970, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 860: loss = 1.7075, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 861: loss = 1.7140, acc = 0.47949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 862: loss = 1.7342, acc = 0.47559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 863: loss = 1.6297, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 864: loss = 1.7430, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 865: loss = 1.8150, acc = 0.47461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 866: loss = 1.7794, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 867: loss = 1.6258, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 868: loss = 1.8361, acc = 0.45703\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 869: loss = 1.7803, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 870: loss = 1.8058, acc = 0.46777\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 871: loss = 1.7457, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 872: loss = 1.7134, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 873: loss = 1.7300, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 874: loss = 1.7517, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 875: loss = 1.7589, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 876: loss = 1.7222, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 877: loss = 1.6893, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 878: loss = 1.6982, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 879: loss = 1.7931, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 880: loss = 1.7317, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 881: loss = 1.7055, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 882: loss = 1.5836, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 883: loss = 1.7268, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 884: loss = 1.7588, acc = 0.46387\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 885: loss = 1.8234, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 886: loss = 1.8264, acc = 0.45605\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 887: loss = 1.7444, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 888: loss = 1.8170, acc = 0.46582\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 889: loss = 1.7655, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 890: loss = 1.7388, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 891: loss = 1.8137, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 892: loss = 1.7542, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 893: loss = 1.6870, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 894: loss = 1.6961, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 895: loss = 1.7367, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 896: loss = 1.7711, acc = 0.48340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 897: loss = 1.7044, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 898: loss = 1.6709, acc = 0.51953\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 899: loss = 1.6651, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 900: loss = 1.7964, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 901: loss = 1.6957, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 902: loss = 1.7187, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 903: loss = 1.6956, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 904: loss = 1.6897, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 905: loss = 1.8265, acc = 0.47461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 906: loss = 1.7151, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 907: loss = 1.8054, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 908: loss = 1.7719, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 909: loss = 1.6349, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 910: loss = 1.7332, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 911: loss = 1.6811, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 912: loss = 1.7644, acc = 0.46973\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 913: loss = 1.6766, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 914: loss = 1.6655, acc = 0.51758\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 915: loss = 1.7189, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 916: loss = 1.7254, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 917: loss = 1.6969, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 918: loss = 1.7382, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 919: loss = 1.6832, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 920: loss = 1.8017, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 921: loss = 1.7368, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 922: loss = 1.7224, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 923: loss = 1.6997, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 924: loss = 1.7942, acc = 0.47168\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 925: loss = 1.7053, acc = 0.47461\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 926: loss = 1.7288, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 927: loss = 1.6822, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 928: loss = 1.7209, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 929: loss = 1.7438, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 930: loss = 1.6731, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 931: loss = 1.6819, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 932: loss = 1.6580, acc = 0.51758\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 933: loss = 1.7208, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 934: loss = 1.7062, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 935: loss = 1.6691, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 936: loss = 1.6942, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 937: loss = 1.6990, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 938: loss = 1.7559, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 939: loss = 1.6828, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 940: loss = 1.6075, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 941: loss = 1.7069, acc = 0.50391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 942: loss = 1.6229, acc = 0.53125\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 943: loss = 1.6894, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 944: loss = 1.6966, acc = 0.49707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 945: loss = 1.7212, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 946: loss = 1.6916, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 947: loss = 1.6747, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 948: loss = 1.7277, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 949: loss = 1.7355, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 950: loss = 1.6690, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 951: loss = 1.6204, acc = 0.51465\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 952: loss = 1.6669, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 953: loss = 1.6806, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 954: loss = 1.6830, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 955: loss = 1.7017, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 956: loss = 1.6076, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 957: loss = 1.7475, acc = 0.48340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 958: loss = 1.7400, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 959: loss = 1.6161, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 960: loss = 1.6771, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 961: loss = 1.7035, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 962: loss = 1.6565, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 963: loss = 1.6554, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 964: loss = 1.6659, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 965: loss = 1.6821, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 966: loss = 1.6273, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 967: loss = 1.7475, acc = 0.47559\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 968: loss = 1.6346, acc = 0.51465\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 969: loss = 1.6255, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 970: loss = 1.5789, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 971: loss = 1.5864, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 972: loss = 1.6703, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 973: loss = 1.6051, acc = 0.53613\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 974: loss = 1.5796, acc = 0.53516\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 975: loss = 1.6565, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 976: loss = 1.4847, acc = 0.54102\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 977: loss = 1.7558, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 978: loss = 1.7367, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 979: loss = 1.7397, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 980: loss = 1.6110, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 981: loss = 1.6952, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 982: loss = 1.7172, acc = 0.48340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 983: loss = 1.7030, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 984: loss = 1.6997, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 985: loss = 1.7415, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 986: loss = 1.6710, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 987: loss = 1.5964, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 988: loss = 1.6307, acc = 0.52051\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 989: loss = 1.6222, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 990: loss = 1.6309, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 991: loss = 1.6657, acc = 0.52344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 992: loss = 1.6658, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 993: loss = 1.7399, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 994: loss = 1.6881, acc = 0.48535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 995: loss = 1.6355, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 996: loss = 1.6660, acc = 0.52441\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 997: loss = 1.5903, acc = 0.50000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 998: loss = 1.7239, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 999: loss = 1.5792, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1000: loss = 1.7133, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1001: loss = 1.6897, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1002: loss = 1.7019, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1003: loss = 1.7430, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1004: loss = 1.6714, acc = 0.52051\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1005: loss = 1.6238, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1006: loss = 1.6963, acc = 0.49707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1007: loss = 1.6770, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1008: loss = 1.7642, acc = 0.47754\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1009: loss = 1.6596, acc = 0.50000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1010: loss = 1.7071, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1011: loss = 1.7123, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1012: loss = 1.7066, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1013: loss = 1.7036, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1014: loss = 1.6987, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1015: loss = 1.7899, acc = 0.45996\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1016: loss = 1.6707, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1017: loss = 1.7157, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1018: loss = 1.6828, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1019: loss = 1.7224, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1020: loss = 1.5857, acc = 0.52344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1021: loss = 1.6499, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1022: loss = 1.6085, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1023: loss = 1.6293, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1024: loss = 1.6896, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1025: loss = 1.6771, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1026: loss = 1.6878, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1027: loss = 1.5863, acc = 0.52246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1028: loss = 1.7292, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1029: loss = 1.5384, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1030: loss = 1.6277, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1031: loss = 1.6178, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1032: loss = 1.6236, acc = 0.51660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1033: loss = 1.7557, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1034: loss = 1.6595, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1035: loss = 1.6376, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1036: loss = 1.5894, acc = 0.53027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1037: loss = 1.6265, acc = 0.51465\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1038: loss = 1.6207, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1039: loss = 1.5621, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1040: loss = 1.7041, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1041: loss = 1.6829, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1042: loss = 1.6567, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1043: loss = 1.6408, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1044: loss = 1.6905, acc = 0.49707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1045: loss = 1.6064, acc = 0.52930\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1046: loss = 1.6577, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1047: loss = 1.6849, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1048: loss = 1.6595, acc = 0.51660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1049: loss = 1.6876, acc = 0.51953\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1050: loss = 1.6028, acc = 0.51855\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1051: loss = 1.5888, acc = 0.53027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1052: loss = 1.6260, acc = 0.52246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1053: loss = 1.7296, acc = 0.49707\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1054: loss = 1.6515, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1055: loss = 1.7538, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1056: loss = 1.8059, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1057: loss = 1.6456, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1058: loss = 1.6861, acc = 0.48340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1059: loss = 1.7881, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1060: loss = 1.5945, acc = 0.51855\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1061: loss = 1.6195, acc = 0.53613\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1062: loss = 1.7134, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1063: loss = 1.6278, acc = 0.51465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1064: loss = 1.6963, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1065: loss = 1.7574, acc = 0.46680\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1066: loss = 1.6468, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1067: loss = 1.7546, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1068: loss = 1.6564, acc = 0.51562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1069: loss = 1.7919, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1070: loss = 1.6112, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1071: loss = 1.6832, acc = 0.46582\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1072: loss = 1.5681, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1073: loss = 1.7242, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1074: loss = 1.6083, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1075: loss = 1.6215, acc = 0.52246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1076: loss = 1.6169, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1077: loss = 1.5919, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1078: loss = 1.5882, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1079: loss = 1.6947, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1080: loss = 1.6629, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1081: loss = 1.8217, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1082: loss = 1.7097, acc = 0.48535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1083: loss = 1.6329, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1084: loss = 1.6825, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1085: loss = 1.6647, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1086: loss = 1.7036, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1087: loss = 1.6968, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1088: loss = 1.6946, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1089: loss = 1.6366, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1090: loss = 1.6044, acc = 0.54297\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1091: loss = 1.6698, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1092: loss = 1.7317, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1093: loss = 1.7479, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1094: loss = 1.7256, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1095: loss = 1.6112, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1096: loss = 1.6291, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1097: loss = 1.6345, acc = 0.49805\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1098: loss = 1.6686, acc = 0.51660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1099: loss = 1.7444, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1100: loss = 1.5894, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1101: loss = 1.6243, acc = 0.51465\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1102: loss = 1.6802, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1103: loss = 1.5887, acc = 0.52637\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1104: loss = 1.6189, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1105: loss = 1.5977, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1106: loss = 1.5285, acc = 0.54492\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1107: loss = 1.7319, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1108: loss = 1.6209, acc = 0.52344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1109: loss = 1.5398, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1110: loss = 1.6816, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1111: loss = 1.6038, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1112: loss = 1.6667, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1113: loss = 1.6313, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1114: loss = 1.7525, acc = 0.49219\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1115: loss = 1.6754, acc = 0.48047\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1116: loss = 1.6178, acc = 0.52344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1117: loss = 1.7193, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1118: loss = 1.6470, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1119: loss = 1.5833, acc = 0.51758\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1120: loss = 1.6325, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1121: loss = 1.7511, acc = 0.48438\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1122: loss = 1.7251, acc = 0.47852\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1123: loss = 1.6924, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1124: loss = 1.5883, acc = 0.51562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1125: loss = 1.4982, acc = 0.53613\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1126: loss = 1.6725, acc = 0.48633\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1127: loss = 1.6575, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1128: loss = 1.6920, acc = 0.48730\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1129: loss = 1.6069, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1130: loss = 1.7524, acc = 0.45801\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1131: loss = 1.6878, acc = 0.48926\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1132: loss = 1.6112, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1133: loss = 1.7094, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1134: loss = 1.6192, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1135: loss = 1.5655, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1136: loss = 1.7393, acc = 0.48340\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1137: loss = 1.6551, acc = 0.51660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1138: loss = 1.6080, acc = 0.52246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1139: loss = 1.7400, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1140: loss = 1.5847, acc = 0.53809\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1141: loss = 1.6789, acc = 0.48242\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1142: loss = 1.7512, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1143: loss = 1.7778, acc = 0.47363\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1144: loss = 1.6286, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1145: loss = 1.7717, acc = 0.47656\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1146: loss = 1.7328, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1147: loss = 1.5936, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1148: loss = 1.6048, acc = 0.51562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1149: loss = 1.6634, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1150: loss = 1.6500, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1151: loss = 1.7324, acc = 0.49414\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1152: loss = 1.6201, acc = 0.52051\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1153: loss = 1.6363, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1154: loss = 1.6159, acc = 0.52637\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1155: loss = 1.6494, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1156: loss = 1.6387, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1157: loss = 1.6871, acc = 0.52051\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1158: loss = 1.6576, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1159: loss = 1.6340, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1160: loss = 1.6656, acc = 0.51562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1161: loss = 1.5492, acc = 0.55566\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1162: loss = 1.5300, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1163: loss = 1.6291, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1164: loss = 1.6154, acc = 0.52344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1165: loss = 1.5623, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1166: loss = 1.6304, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1167: loss = 1.6165, acc = 0.52637\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1168: loss = 1.6123, acc = 0.53125\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1169: loss = 1.6114, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1170: loss = 1.5896, acc = 0.53027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1171: loss = 1.5980, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1172: loss = 1.6607, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1173: loss = 1.7229, acc = 0.50195\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1174: loss = 1.7702, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1175: loss = 1.6795, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1176: loss = 1.6780, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1177: loss = 1.6271, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1178: loss = 1.6005, acc = 0.52441\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1179: loss = 1.5824, acc = 0.53516\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1180: loss = 1.6514, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1181: loss = 1.5576, acc = 0.52637\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1182: loss = 1.6733, acc = 0.48828\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1183: loss = 1.6546, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1184: loss = 1.5544, acc = 0.52539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1185: loss = 1.5478, acc = 0.51855\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1186: loss = 1.5756, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1187: loss = 1.5928, acc = 0.53613\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1188: loss = 1.6037, acc = 0.50391\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1189: loss = 1.6122, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1190: loss = 1.6270, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1191: loss = 1.6510, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1192: loss = 1.5415, acc = 0.54785\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1193: loss = 1.6684, acc = 0.49121\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1194: loss = 1.6467, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1195: loss = 1.5441, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1196: loss = 1.6829, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1197: loss = 1.6431, acc = 0.50488\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1198: loss = 1.5608, acc = 0.54297\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1199: loss = 1.5794, acc = 0.53027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1200: loss = 1.6606, acc = 0.51172\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1201: loss = 1.6086, acc = 0.50781\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1202: loss = 1.5748, acc = 0.52441\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1203: loss = 1.6201, acc = 0.51953\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1204: loss = 1.6562, acc = 0.52246\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1205: loss = 1.6240, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1206: loss = 1.6980, acc = 0.49023\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1207: loss = 1.6234, acc = 0.49609\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1208: loss = 1.5717, acc = 0.52344\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1209: loss = 1.6123, acc = 0.52051\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1210: loss = 1.6273, acc = 0.47949\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1211: loss = 1.6486, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1212: loss = 1.5524, acc = 0.53027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1213: loss = 1.6131, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1214: loss = 1.6284, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1215: loss = 1.6701, acc = 0.50293\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1216: loss = 1.6236, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1217: loss = 1.6254, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1218: loss = 1.5942, acc = 0.52441\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1219: loss = 1.5617, acc = 0.53711\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1220: loss = 1.6260, acc = 0.49902\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1221: loss = 1.6103, acc = 0.51660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1222: loss = 1.6025, acc = 0.51758\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1223: loss = 1.6376, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1224: loss = 1.6575, acc = 0.51855\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1225: loss = 1.6080, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1226: loss = 1.6390, acc = 0.50879\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1227: loss = 1.6164, acc = 0.49512\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1228: loss = 1.6354, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1229: loss = 1.6430, acc = 0.51270\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1230: loss = 1.6568, acc = 0.48535\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1231: loss = 1.5418, acc = 0.55078\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1232: loss = 1.5852, acc = 0.52051\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1233: loss = 1.6778, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1234: loss = 1.5514, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1235: loss = 1.6391, acc = 0.50977\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1236: loss = 1.6389, acc = 0.51465\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1237: loss = 1.6078, acc = 0.51562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1238: loss = 1.6070, acc = 0.53711\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1239: loss = 1.6081, acc = 0.51562\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1240: loss = 1.6448, acc = 0.51953\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1241: loss = 1.6795, acc = 0.50000\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1242: loss = 1.7527, acc = 0.49316\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1243: loss = 1.6690, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1244: loss = 1.6508, acc = 0.50098\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1245: loss = 1.6069, acc = 0.53320\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1246: loss = 1.7612, acc = 0.48145\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1247: loss = 1.6060, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1248: loss = 1.6327, acc = 0.53711\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1249: loss = 1.6553, acc = 0.51660\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1250: loss = 1.6383, acc = 0.51367\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1251: loss = 1.5720, acc = 0.52734\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1252: loss = 1.6124, acc = 0.50586\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1253: loss = 1.5560, acc = 0.53516\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1254: loss = 1.6209, acc = 0.51074\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1255: loss = 1.5432, acc = 0.53027\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1256: loss = 1.6577, acc = 0.51855\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1257: loss = 1.6077, acc = 0.53223\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1258: loss = 1.5776, acc = 0.52930\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1259: loss = 1.6176, acc = 0.52539\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1260: loss = 1.5651, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1261: loss = 1.6188, acc = 0.52148\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1262: loss = 1.5707, acc = 0.53613\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1263: loss = 1.5322, acc = 0.53418\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1264: loss = 1.5662, acc = 0.53809\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1265: loss = 1.5853, acc = 0.52832\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1266: loss = 1.5909, acc = 0.52637\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1267: loss = 1.6818, acc = 0.50684\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1268: loss = 1.5405, acc = 0.54785\n",
      "\u001b[36malgo-1-ntdvh_1  |\u001b[0m Batch 1269: loss = 1.5685, acc = 0.51660\n"
     ]
    }
   ],
   "source": [
    "inputs = {'training': f'file://{data_dir}'}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explain the values of `--data_dir` and `--model_dir` with more details:\n",
    "\n",
    "- **/opt/ml/input/data/training** is the directory inside the container where the training data is downloaded. The data is downloaded to this folder because `training` is the channel name defined in ```estimator.fit({'training': inputs})```. See [training data](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-running-container-trainingdata) for more information. \n",
    "\n",
    "- **/opt/ml/model** use this directory to save models, checkpoints, or any other data. Any data saved in this folder is saved in the S3 bucket defined for training. See [model data](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html#your-algorithms-training-algo-envvariables) for more information.\n",
    "\n",
    "### Reading additional information from the container\n",
    "\n",
    "Often, a user script needs additional information from the container that is not available in ```hyperparameters```.\n",
    "SageMaker containers write this information as **environment variables** that are available inside the script.\n",
    "\n",
    "For example, the example above can read information about the `training` channel provided in the training job request by adding the environment variable `SM_CHANNEL_TRAINING` as the default value for the `--data_dir` argument:\n",
    "\n",
    "```python\n",
    "if __name__ == '__main__':\n",
    "  parser = argparse.ArgumentParser()\n",
    "  # reads input channels training and testing from the environment variables\n",
    "  parser.add_argument('--data_dir', type=str, default=os.environ['SM_CHANNEL_TRAINING'])\n",
    "```\n",
    "\n",
    "Script mode displays the list of available environment variables in the training logs. You can find the [entire list here](https://github.com/aws/sagemaker-containers/blob/master/README.rst#list-of-provided-environment-variables-by-sagemaker-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training in SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you test the training job locally, upload the dataset to an S3 bucket so SageMaker can access the data during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "inputs = sagemaker.Session().upload_data(path='sherlock', key_prefix='datasets/sherlock')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned variable inputs above is a string with a S3 location which SageMaker Tranining has permissions\n",
    "to read data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-951232522638/datasets/sherlock'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train in SageMaker:\n",
    "- change the estimator argument `train_instance_type` to any SageMaker ml instance available for training.\n",
    "- set the `training` channel to a S3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-06 01:11:38 Starting - Starting the training job...\n",
      "2019-08-06 01:11:40 Starting - Launching requested ML instances.........\n",
      "2019-08-06 01:13:12 Starting - Preparing the instances for training...\n",
      "2019-08-06 01:14:04 Downloading - Downloading input data...\n",
      "2019-08-06 01:14:21 Training - Downloading the training image.....\n",
      "\u001b[31m2019-08-06 01:15:15,744 sagemaker-containers INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[31m2019-08-06 01:15:15,749 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-06 01:15:16,248 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-06 01:15:16,264 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-06 01:15:16,281 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[31m2019-08-06 01:15:16,294 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/model\",\n",
      "        \"epochs\": 1,\n",
      "        \"data_dir\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"tensorflow-training-2019-08-06-01-11-37-989\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[31mSM_HPS={\"data_dir\":\"/opt/ml/input/data/training\",\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/model\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"data_dir\":\"/opt/ml/input/data/training\",\"epochs\":1,\"model_dir\":\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/model\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"tensorflow-training-2019-08-06-01-11-37-989\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--data_dir\",\"/opt/ml/input/data/training\",\"--epochs\",\"1\",\"--model_dir\",\"s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/model\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HP_MODEL_DIR=s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/model\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[31mSM_HP_DATA_DIR=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python36.zip:/usr/local/lib/python3.6:/usr/local/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/local/bin/python3.6 train.py --data_dir /opt/ml/input/data/training --epochs 1 --model_dir s3://sagemaker-us-east-1-951232522638/tensorflow-training-2019-08-06-01-11-37-989/model\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31mUsing TensorFlow backend.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mColocations handled automatically by placer.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mLayer (type)                 Output Shape              Param #   \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31membedding_1 (Embedding)      (16, 64, 512)             49664     \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mlstm_1 (LSTM)                (16, 64, 256)             787456    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_1 (Dropout)          (16, 64, 256)             0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mlstm_2 (LSTM)                (16, 64, 256)             525312    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_2 (Dropout)          (16, 64, 256)             0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mlstm_3 (LSTM)                (16, 64, 256)             525312    \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mdropout_3 (Dropout)          (16, 64, 256)             0         \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mtime_distributed_1 (TimeDist (16, 64, 97)              24929     \u001b[0m\n",
      "\u001b[31m_________________________________________________________________\u001b[0m\n",
      "\u001b[31mactivation_1 (Activation)    (16, 64, 97)              0         \u001b[0m\n",
      "\u001b[31m=================================================================\u001b[0m\n",
      "\u001b[31mTotal params: 1,912,673\u001b[0m\n",
      "\u001b[31mTrainable params: 1,912,673\u001b[0m\n",
      "\u001b[31mNon-trainable params: 0\u001b[0m\n",
      "\u001b[31m_________________________________________________________________\n",
      "\u001b[0m\n",
      "\u001b[31mEpoch 1/1\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mUse tf.cast instead.\u001b[0m\n",
      "\u001b[31mWARNING:tensorflow:From /usr/local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[31mInstructions for updating:\u001b[0m\n",
      "\u001b[31mDeprecated in favor of operator or tf.math.divide.\u001b[0m\n",
      "\u001b[31mBatch 1: loss = 4.5753, acc = 0.00488\u001b[0m\n",
      "\u001b[31mBatch 2: loss = 4.5559, acc = 0.26660\u001b[0m\n",
      "\u001b[31mBatch 3: loss = 4.5142, acc = 0.25488\u001b[0m\n",
      "\u001b[31mBatch 4: loss = 4.3696, acc = 0.28516\u001b[0m\n",
      "\u001b[31mBatch 5: loss = 4.0057, acc = 0.25195\u001b[0m\n",
      "\u001b[31mBatch 6: loss = 3.6427, acc = 0.27148\u001b[0m\n",
      "\u001b[31mBatch 7: loss = 3.4307, acc = 0.26465\u001b[0m\n",
      "\u001b[31mBatch 8: loss = 3.3053, acc = 0.24609\u001b[0m\n",
      "\u001b[31mBatch 9: loss = 3.3613, acc = 0.13672\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2019-08-06 01:15:11 Training - Training image download completed. Training in progress.\u001b[31mBatch 10: loss = 3.2813, acc = 0.14453\u001b[0m\n",
      "\u001b[31mBatch 11: loss = 3.2297, acc = 0.16309\u001b[0m\n",
      "\u001b[31mBatch 12: loss = 3.1750, acc = 0.21973\u001b[0m\n",
      "\u001b[31mBatch 13: loss = 3.0742, acc = 0.23438\u001b[0m\n",
      "\u001b[31mBatch 14: loss = 3.0730, acc = 0.25195\u001b[0m\n",
      "\u001b[31mBatch 15: loss = 3.0202, acc = 0.25684\u001b[0m\n",
      "\u001b[31mBatch 16: loss = 3.0665, acc = 0.24707\u001b[0m\n",
      "\u001b[31mBatch 17: loss = 3.0691, acc = 0.24707\u001b[0m\n",
      "\u001b[31mBatch 18: loss = 3.0796, acc = 0.23730\u001b[0m\n",
      "\u001b[31mBatch 19: loss = 3.0855, acc = 0.24902\u001b[0m\n",
      "\u001b[31mBatch 20: loss = 2.9943, acc = 0.24609\u001b[0m\n",
      "\u001b[31mBatch 21: loss = 3.0144, acc = 0.22363\u001b[0m\n",
      "\u001b[31mBatch 22: loss = 2.9809, acc = 0.23047\u001b[0m\n",
      "\u001b[31mBatch 23: loss = 3.0437, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 24: loss = 3.0613, acc = 0.22070\u001b[0m\n",
      "\u001b[31mBatch 25: loss = 3.0478, acc = 0.23535\u001b[0m\n",
      "\u001b[31mBatch 26: loss = 3.0594, acc = 0.23633\u001b[0m\n",
      "\u001b[31mBatch 27: loss = 2.9946, acc = 0.24023\u001b[0m\n",
      "\u001b[31mBatch 28: loss = 3.0302, acc = 0.24121\u001b[0m\n",
      "\u001b[31mBatch 29: loss = 3.0517, acc = 0.23730\u001b[0m\n",
      "\u001b[31mBatch 30: loss = 3.0060, acc = 0.24707\u001b[0m\n",
      "\u001b[31mBatch 31: loss = 2.9614, acc = 0.24902\u001b[0m\n",
      "\u001b[31mBatch 32: loss = 3.0351, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 33: loss = 2.9475, acc = 0.26562\u001b[0m\n",
      "\u001b[31mBatch 34: loss = 3.0032, acc = 0.24219\u001b[0m\n",
      "\u001b[31mBatch 35: loss = 2.9818, acc = 0.24316\u001b[0m\n",
      "\u001b[31mBatch 36: loss = 3.0052, acc = 0.24414\u001b[0m\n",
      "\u001b[31mBatch 37: loss = 3.0388, acc = 0.23633\u001b[0m\n",
      "\u001b[31mBatch 38: loss = 2.9924, acc = 0.23535\u001b[0m\n",
      "\u001b[31mBatch 39: loss = 3.0318, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 40: loss = 3.0552, acc = 0.25195\u001b[0m\n",
      "\u001b[31mBatch 41: loss = 2.9712, acc = 0.25977\u001b[0m\n",
      "\u001b[31mBatch 42: loss = 3.0219, acc = 0.24805\u001b[0m\n",
      "\u001b[31mBatch 43: loss = 2.9997, acc = 0.23438\u001b[0m\n",
      "\u001b[31mBatch 44: loss = 3.0350, acc = 0.22949\u001b[0m\n",
      "\u001b[31mBatch 45: loss = 3.0845, acc = 0.24414\u001b[0m\n",
      "\u001b[31mBatch 46: loss = 2.9965, acc = 0.24414\u001b[0m\n",
      "\u001b[31mBatch 47: loss = 3.0586, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 48: loss = 3.0358, acc = 0.24121\u001b[0m\n",
      "\u001b[31mBatch 49: loss = 3.0461, acc = 0.24707\u001b[0m\n",
      "\u001b[31mBatch 50: loss = 3.0192, acc = 0.24609\u001b[0m\n",
      "\u001b[31mBatch 51: loss = 3.0785, acc = 0.25098\u001b[0m\n",
      "\u001b[31mBatch 52: loss = 2.9312, acc = 0.26074\u001b[0m\n",
      "\u001b[31mBatch 53: loss = 3.0723, acc = 0.22754\u001b[0m\n",
      "\u001b[31mBatch 54: loss = 3.0561, acc = 0.24316\u001b[0m\n",
      "\u001b[31mBatch 55: loss = 3.0289, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 56: loss = 3.0314, acc = 0.22754\u001b[0m\n",
      "\u001b[31mBatch 57: loss = 2.9972, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 58: loss = 3.0386, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 59: loss = 3.0022, acc = 0.23242\u001b[0m\n",
      "\u001b[31mBatch 60: loss = 3.0095, acc = 0.23047\u001b[0m\n",
      "\u001b[31mBatch 61: loss = 2.9851, acc = 0.23145\u001b[0m\n",
      "\u001b[31mBatch 62: loss = 3.0162, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 63: loss = 3.0530, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 64: loss = 3.0207, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 65: loss = 3.0551, acc = 0.23145\u001b[0m\n",
      "\u001b[31mBatch 66: loss = 2.9905, acc = 0.23730\u001b[0m\n",
      "\u001b[31mBatch 67: loss = 2.9814, acc = 0.23730\u001b[0m\n",
      "\u001b[31mBatch 68: loss = 3.0040, acc = 0.22949\u001b[0m\n",
      "\u001b[31mBatch 69: loss = 3.0696, acc = 0.23145\u001b[0m\n",
      "\u001b[31mBatch 70: loss = 2.9820, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 71: loss = 3.0145, acc = 0.22461\u001b[0m\n",
      "\u001b[31mBatch 72: loss = 2.9724, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 73: loss = 2.9944, acc = 0.22656\u001b[0m\n",
      "\u001b[31mBatch 74: loss = 3.0201, acc = 0.22754\u001b[0m\n",
      "\u001b[31mBatch 75: loss = 2.9500, acc = 0.23535\u001b[0m\n",
      "\u001b[31mBatch 76: loss = 2.9824, acc = 0.24121\u001b[0m\n",
      "\u001b[31mBatch 77: loss = 3.0341, acc = 0.23633\u001b[0m\n",
      "\u001b[31mBatch 78: loss = 2.9694, acc = 0.24414\u001b[0m\n",
      "\u001b[31mBatch 79: loss = 3.0158, acc = 0.23242\u001b[0m\n",
      "\u001b[31mBatch 80: loss = 2.9271, acc = 0.25000\u001b[0m\n",
      "\u001b[31mBatch 81: loss = 3.0308, acc = 0.22168\u001b[0m\n",
      "\u001b[31mBatch 82: loss = 2.9882, acc = 0.23047\u001b[0m\n",
      "\u001b[31mBatch 83: loss = 3.0026, acc = 0.24023\u001b[0m\n",
      "\u001b[31mBatch 84: loss = 2.9566, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 85: loss = 2.9600, acc = 0.23633\u001b[0m\n",
      "\u001b[31mBatch 86: loss = 3.0470, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 87: loss = 3.0246, acc = 0.22754\u001b[0m\n",
      "\u001b[31mBatch 88: loss = 2.9861, acc = 0.23535\u001b[0m\n",
      "\u001b[31mBatch 89: loss = 3.0384, acc = 0.22266\u001b[0m\n",
      "\u001b[31mBatch 90: loss = 2.9937, acc = 0.23438\u001b[0m\n",
      "\u001b[31mBatch 91: loss = 3.0301, acc = 0.22070\u001b[0m\n",
      "\u001b[31mBatch 92: loss = 3.0237, acc = 0.22656\u001b[0m\n",
      "\u001b[31mBatch 93: loss = 2.9829, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 94: loss = 3.0199, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 95: loss = 3.0104, acc = 0.22656\u001b[0m\n",
      "\u001b[31mBatch 96: loss = 3.0360, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 97: loss = 3.0262, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 98: loss = 2.9538, acc = 0.22363\u001b[0m\n",
      "\u001b[31mBatch 99: loss = 2.9870, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 100: loss = 3.0115, acc = 0.24121\u001b[0m\n",
      "\u001b[31mBatch 101: loss = 3.0020, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 102: loss = 2.9869, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 103: loss = 2.9745, acc = 0.22754\u001b[0m\n",
      "\u001b[31mBatch 104: loss = 2.9944, acc = 0.23047\u001b[0m\n",
      "\u001b[31mBatch 105: loss = 2.9829, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 106: loss = 2.9537, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 107: loss = 2.9912, acc = 0.22852\u001b[0m\n",
      "\u001b[31mBatch 108: loss = 3.0026, acc = 0.22852\u001b[0m\n",
      "\u001b[31mBatch 109: loss = 3.0112, acc = 0.24121\u001b[0m\n",
      "\u001b[31mBatch 110: loss = 2.9315, acc = 0.24414\u001b[0m\n",
      "\u001b[31mBatch 111: loss = 3.0914, acc = 0.24609\u001b[0m\n",
      "\u001b[31mBatch 112: loss = 2.9700, acc = 0.23242\u001b[0m\n",
      "\u001b[31mBatch 113: loss = 2.9986, acc = 0.25195\u001b[0m\n",
      "\u001b[31mBatch 114: loss = 2.9905, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 115: loss = 3.0563, acc = 0.22949\u001b[0m\n",
      "\u001b[31mBatch 116: loss = 3.0458, acc = 0.22266\u001b[0m\n",
      "\u001b[31mBatch 117: loss = 2.9810, acc = 0.22461\u001b[0m\n",
      "\u001b[31mBatch 118: loss = 3.0117, acc = 0.24414\u001b[0m\n",
      "\u001b[31mBatch 119: loss = 2.9906, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 120: loss = 3.0232, acc = 0.22363\u001b[0m\n",
      "\u001b[31mBatch 121: loss = 2.9833, acc = 0.23145\u001b[0m\n",
      "\u001b[31mBatch 122: loss = 3.0013, acc = 0.23633\u001b[0m\n",
      "\u001b[31mBatch 123: loss = 3.0138, acc = 0.23535\u001b[0m\n",
      "\u001b[31mBatch 124: loss = 3.0221, acc = 0.22266\u001b[0m\n",
      "\u001b[31mBatch 125: loss = 3.0102, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 126: loss = 2.9686, acc = 0.24707\u001b[0m\n",
      "\u001b[31mBatch 127: loss = 3.0251, acc = 0.24609\u001b[0m\n",
      "\u001b[31mBatch 128: loss = 2.9829, acc = 0.22949\u001b[0m\n",
      "\u001b[31mBatch 129: loss = 2.9617, acc = 0.22949\u001b[0m\n",
      "\u001b[31mBatch 130: loss = 2.9579, acc = 0.23145\u001b[0m\n",
      "\u001b[31mBatch 131: loss = 2.9968, acc = 0.23047\u001b[0m\n",
      "\u001b[31mBatch 132: loss = 3.0045, acc = 0.23340\u001b[0m\n",
      "\u001b[31mBatch 133: loss = 3.0426, acc = 0.22168\u001b[0m\n",
      "\u001b[31mBatch 134: loss = 2.9873, acc = 0.23242\u001b[0m\n",
      "\u001b[31mBatch 135: loss = 3.0929, acc = 0.24512\u001b[0m\n",
      "\u001b[31mBatch 136: loss = 3.0434, acc = 0.23438\u001b[0m\n",
      "\u001b[31mBatch 137: loss = 3.0191, acc = 0.22656\u001b[0m\n",
      "\u001b[31mBatch 138: loss = 3.0589, acc = 0.22266\u001b[0m\n",
      "\u001b[31mBatch 139: loss = 3.0090, acc = 0.22656\u001b[0m\n",
      "\u001b[31mBatch 140: loss = 2.9628, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 141: loss = 2.9849, acc = 0.23438\u001b[0m\n",
      "\u001b[31mBatch 142: loss = 2.9988, acc = 0.22363\u001b[0m\n",
      "\u001b[31mBatch 143: loss = 2.9509, acc = 0.24023\u001b[0m\n",
      "\u001b[31mBatch 144: loss = 2.9993, acc = 0.22559\u001b[0m\n",
      "\u001b[31mBatch 145: loss = 2.9583, acc = 0.22070\u001b[0m\n",
      "\u001b[31mBatch 146: loss = 2.9339, acc = 0.23535\u001b[0m\n",
      "\u001b[31mBatch 147: loss = 2.9559, acc = 0.22363\u001b[0m\n",
      "\u001b[31mBatch 148: loss = 2.9188, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 149: loss = 2.9241, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 150: loss = 2.9075, acc = 0.22949\u001b[0m\n",
      "\u001b[31mBatch 151: loss = 2.9525, acc = 0.23828\u001b[0m\n",
      "\u001b[31mBatch 152: loss = 2.8993, acc = 0.24023\u001b[0m\n",
      "\u001b[31mBatch 153: loss = 2.8991, acc = 0.23926\u001b[0m\n",
      "\u001b[31mBatch 154: loss = 2.9026, acc = 0.24023\u001b[0m\n",
      "\u001b[31mBatch 155: loss = 2.9692, acc = 0.23633\u001b[0m\n",
      "\u001b[31mBatch 156: loss = 2.8776, acc = 0.24805\u001b[0m\n",
      "\u001b[31mBatch 157: loss = 2.7989, acc = 0.25195\u001b[0m\n",
      "\u001b[31mBatch 158: loss = 2.8227, acc = 0.24512\u001b[0m\n",
      "\u001b[31mBatch 159: loss = 2.8597, acc = 0.24512\u001b[0m\n",
      "\u001b[31mBatch 160: loss = 2.7550, acc = 0.26660\u001b[0m\n",
      "\u001b[31mBatch 161: loss = 2.8419, acc = 0.25977\u001b[0m\n",
      "\u001b[31mBatch 162: loss = 2.8110, acc = 0.24805\u001b[0m\n",
      "\u001b[31mBatch 163: loss = 2.8064, acc = 0.25000\u001b[0m\n",
      "\u001b[31mBatch 164: loss = 2.7676, acc = 0.25293\u001b[0m\n",
      "\u001b[31mBatch 165: loss = 2.7493, acc = 0.27051\u001b[0m\n",
      "\u001b[31mBatch 166: loss = 2.7438, acc = 0.26270\u001b[0m\n",
      "\u001b[31mBatch 167: loss = 2.7608, acc = 0.27344\u001b[0m\n",
      "\u001b[31mBatch 168: loss = 2.7247, acc = 0.26172\u001b[0m\n",
      "\u001b[31mBatch 169: loss = 2.7046, acc = 0.26367\u001b[0m\n",
      "\u001b[31mBatch 170: loss = 2.6540, acc = 0.27246\u001b[0m\n",
      "\u001b[31mBatch 171: loss = 2.8486, acc = 0.24609\u001b[0m\n",
      "\u001b[31mBatch 172: loss = 2.6121, acc = 0.30078\u001b[0m\n",
      "\u001b[31mBatch 173: loss = 2.6792, acc = 0.27637\u001b[0m\n",
      "\u001b[31mBatch 174: loss = 2.6927, acc = 0.26367\u001b[0m\n",
      "\u001b[31mBatch 175: loss = 2.6804, acc = 0.26953\u001b[0m\n",
      "\u001b[31mBatch 176: loss = 2.6632, acc = 0.27734\u001b[0m\n",
      "\u001b[31mBatch 177: loss = 2.6984, acc = 0.27148\u001b[0m\n",
      "\u001b[31mBatch 178: loss = 2.6586, acc = 0.27441\u001b[0m\n",
      "\u001b[31mBatch 179: loss = 2.6282, acc = 0.27930\u001b[0m\n",
      "\u001b[31mBatch 180: loss = 2.7427, acc = 0.26172\u001b[0m\n",
      "\u001b[31mBatch 181: loss = 2.7100, acc = 0.26953\u001b[0m\n",
      "\u001b[31mBatch 182: loss = 2.7111, acc = 0.26855\u001b[0m\n",
      "\u001b[31mBatch 183: loss = 2.5785, acc = 0.27539\u001b[0m\n",
      "\u001b[31mBatch 184: loss = 2.7387, acc = 0.28320\u001b[0m\n",
      "\u001b[31mBatch 185: loss = 2.6456, acc = 0.28320\u001b[0m\n",
      "\u001b[31mBatch 186: loss = 2.5827, acc = 0.29785\u001b[0m\n",
      "\u001b[31mBatch 187: loss = 2.5760, acc = 0.30566\u001b[0m\n",
      "\u001b[31mBatch 188: loss = 2.5965, acc = 0.28125\u001b[0m\n",
      "\u001b[31mBatch 189: loss = 2.6770, acc = 0.27148\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBatch 190: loss = 2.5372, acc = 0.30273\u001b[0m\n",
      "\u001b[31mBatch 191: loss = 2.5891, acc = 0.28711\u001b[0m\n",
      "\u001b[31mBatch 192: loss = 2.5545, acc = 0.31055\u001b[0m\n",
      "\u001b[31mBatch 193: loss = 2.5352, acc = 0.31348\u001b[0m\n",
      "\u001b[31mBatch 194: loss = 2.5111, acc = 0.31152\u001b[0m\n",
      "\u001b[31mBatch 195: loss = 2.4848, acc = 0.31738\u001b[0m\n",
      "\u001b[31mBatch 196: loss = 2.4978, acc = 0.29785\u001b[0m\n",
      "\u001b[31mBatch 197: loss = 2.5141, acc = 0.29883\u001b[0m\n",
      "\u001b[31mBatch 198: loss = 2.5707, acc = 0.29297\u001b[0m\n",
      "\u001b[31mBatch 199: loss = 2.4941, acc = 0.31836\u001b[0m\n",
      "\u001b[31mBatch 200: loss = 2.5923, acc = 0.29492\u001b[0m\n",
      "\u001b[31mBatch 201: loss = 2.4563, acc = 0.32617\u001b[0m\n",
      "\u001b[31mBatch 202: loss = 2.5391, acc = 0.31152\u001b[0m\n",
      "\u001b[31mBatch 203: loss = 2.6007, acc = 0.30078\u001b[0m\n",
      "\u001b[31mBatch 204: loss = 2.5293, acc = 0.30371\u001b[0m\n",
      "\u001b[31mBatch 205: loss = 2.4706, acc = 0.33398\u001b[0m\n",
      "\u001b[31mBatch 206: loss = 2.5158, acc = 0.33301\u001b[0m\n",
      "\u001b[31mBatch 207: loss = 2.5410, acc = 0.30176\u001b[0m\n",
      "\u001b[31mBatch 208: loss = 2.5038, acc = 0.31934\u001b[0m\n",
      "\u001b[31mBatch 209: loss = 2.5244, acc = 0.31836\u001b[0m\n",
      "\u001b[31mBatch 210: loss = 2.5338, acc = 0.30469\u001b[0m\n",
      "\u001b[31mBatch 211: loss = 2.4322, acc = 0.32812\u001b[0m\n",
      "\u001b[31mBatch 212: loss = 2.4743, acc = 0.32227\u001b[0m\n",
      "\u001b[31mBatch 213: loss = 2.5211, acc = 0.30469\u001b[0m\n",
      "\u001b[31mBatch 214: loss = 2.4419, acc = 0.29395\u001b[0m\n",
      "\u001b[31mBatch 215: loss = 2.4427, acc = 0.30273\u001b[0m\n",
      "\u001b[31mBatch 216: loss = 2.4507, acc = 0.32324\u001b[0m\n",
      "\u001b[31mBatch 217: loss = 2.4604, acc = 0.32227\u001b[0m\n",
      "\u001b[31mBatch 218: loss = 2.3799, acc = 0.34082\u001b[0m\n",
      "\u001b[31mBatch 219: loss = 2.4189, acc = 0.33203\u001b[0m\n",
      "\u001b[31mBatch 220: loss = 2.4141, acc = 0.33984\u001b[0m\n",
      "\u001b[31mBatch 221: loss = 2.3757, acc = 0.34180\u001b[0m\n",
      "\u001b[31mBatch 222: loss = 2.4532, acc = 0.30566\u001b[0m\n",
      "\u001b[31mBatch 223: loss = 2.3319, acc = 0.34863\u001b[0m\n",
      "\u001b[31mBatch 224: loss = 2.3805, acc = 0.32324\u001b[0m\n",
      "\u001b[31mBatch 225: loss = 2.4100, acc = 0.33496\u001b[0m\n",
      "\u001b[31mBatch 226: loss = 2.2977, acc = 0.35156\u001b[0m\n",
      "\u001b[31mBatch 227: loss = 2.3592, acc = 0.33398\u001b[0m\n",
      "\u001b[31mBatch 228: loss = 2.4042, acc = 0.33594\u001b[0m\n",
      "\u001b[31mBatch 229: loss = 2.3682, acc = 0.32227\u001b[0m\n",
      "\u001b[31mBatch 230: loss = 2.3774, acc = 0.34082\u001b[0m\n",
      "\u001b[31mBatch 231: loss = 2.4000, acc = 0.34668\u001b[0m\n",
      "\u001b[31mBatch 232: loss = 2.3311, acc = 0.34375\u001b[0m\n",
      "\u001b[31mBatch 233: loss = 2.3218, acc = 0.34668\u001b[0m\n",
      "\u001b[31mBatch 234: loss = 2.4007, acc = 0.33203\u001b[0m\n",
      "\u001b[31mBatch 235: loss = 2.3517, acc = 0.33594\u001b[0m\n",
      "\u001b[31mBatch 236: loss = 2.4065, acc = 0.33887\u001b[0m\n",
      "\u001b[31mBatch 237: loss = 2.3235, acc = 0.34277\u001b[0m\n",
      "\u001b[31mBatch 238: loss = 2.3772, acc = 0.33105\u001b[0m\n",
      "\u001b[31mBatch 239: loss = 2.3366, acc = 0.34570\u001b[0m\n",
      "\u001b[31mBatch 240: loss = 2.3235, acc = 0.36035\u001b[0m\n",
      "\u001b[31mBatch 241: loss = 2.3300, acc = 0.34277\u001b[0m\n",
      "\u001b[31mBatch 242: loss = 2.4148, acc = 0.33105\u001b[0m\n",
      "\u001b[31mBatch 243: loss = 2.2654, acc = 0.36816\u001b[0m\n",
      "\u001b[31mBatch 244: loss = 2.3334, acc = 0.35449\u001b[0m\n",
      "\u001b[31mBatch 245: loss = 2.2867, acc = 0.35059\u001b[0m\n",
      "\u001b[31mBatch 246: loss = 2.3523, acc = 0.33887\u001b[0m\n",
      "\u001b[31mBatch 247: loss = 2.3115, acc = 0.34668\u001b[0m\n",
      "\u001b[31mBatch 248: loss = 2.3048, acc = 0.37207\u001b[0m\n",
      "\u001b[31mBatch 249: loss = 2.2823, acc = 0.35645\u001b[0m\n",
      "\u001b[31mBatch 250: loss = 2.2988, acc = 0.35059\u001b[0m\n",
      "\u001b[31mBatch 251: loss = 2.3051, acc = 0.36426\u001b[0m\n",
      "\u001b[31mBatch 252: loss = 2.2833, acc = 0.34570\u001b[0m\n",
      "\u001b[31mBatch 253: loss = 2.2757, acc = 0.34766\u001b[0m\n",
      "\u001b[31mBatch 254: loss = 2.3097, acc = 0.33691\u001b[0m\n",
      "\u001b[31mBatch 255: loss = 2.2950, acc = 0.37988\u001b[0m\n",
      "\u001b[31mBatch 256: loss = 2.3100, acc = 0.36035\u001b[0m\n",
      "\u001b[31mBatch 257: loss = 2.2799, acc = 0.36328\u001b[0m\n",
      "\u001b[31mBatch 258: loss = 2.3384, acc = 0.34863\u001b[0m\n",
      "\u001b[31mBatch 259: loss = 2.2425, acc = 0.37988\u001b[0m\n",
      "\u001b[31mBatch 260: loss = 2.2738, acc = 0.35254\u001b[0m\n",
      "\u001b[31mBatch 261: loss = 2.2777, acc = 0.34863\u001b[0m\n",
      "\u001b[31mBatch 262: loss = 2.2532, acc = 0.36621\u001b[0m\n",
      "\u001b[31mBatch 263: loss = 2.2439, acc = 0.35645\u001b[0m\n",
      "\u001b[31mBatch 264: loss = 2.2975, acc = 0.34375\u001b[0m\n",
      "\u001b[31mBatch 265: loss = 2.2903, acc = 0.33984\u001b[0m\n",
      "\u001b[31mBatch 266: loss = 2.4033, acc = 0.32324\u001b[0m\n",
      "\u001b[31mBatch 267: loss = 2.2025, acc = 0.37305\u001b[0m\n",
      "\u001b[31mBatch 268: loss = 2.1607, acc = 0.36621\u001b[0m\n",
      "\u001b[31mBatch 269: loss = 2.2716, acc = 0.34766\u001b[0m\n",
      "\u001b[31mBatch 270: loss = 2.2927, acc = 0.33984\u001b[0m\n",
      "\u001b[31mBatch 271: loss = 2.2484, acc = 0.37598\u001b[0m\n",
      "\u001b[31mBatch 272: loss = 2.1986, acc = 0.36426\u001b[0m\n",
      "\u001b[31mBatch 273: loss = 2.1738, acc = 0.38184\u001b[0m\n",
      "\u001b[31mBatch 274: loss = 2.1801, acc = 0.36914\u001b[0m\n",
      "\u001b[31mBatch 275: loss = 2.2101, acc = 0.36230\u001b[0m\n",
      "\u001b[31mBatch 276: loss = 2.2057, acc = 0.36230\u001b[0m\n",
      "\u001b[31mBatch 277: loss = 2.2715, acc = 0.34277\u001b[0m\n",
      "\u001b[31mBatch 278: loss = 2.2523, acc = 0.35645\u001b[0m\n",
      "\u001b[31mBatch 279: loss = 2.2751, acc = 0.33496\u001b[0m\n",
      "\u001b[31mBatch 280: loss = 2.2910, acc = 0.36035\u001b[0m\n",
      "\u001b[31mBatch 281: loss = 2.2308, acc = 0.35449\u001b[0m\n",
      "\u001b[31mBatch 282: loss = 2.2419, acc = 0.35156\u001b[0m\n",
      "\u001b[31mBatch 283: loss = 2.2327, acc = 0.37500\u001b[0m\n",
      "\u001b[31mBatch 284: loss = 2.2181, acc = 0.37500\u001b[0m\n",
      "\u001b[31mBatch 285: loss = 2.2542, acc = 0.34473\u001b[0m\n",
      "\u001b[31mBatch 286: loss = 2.2224, acc = 0.36719\u001b[0m\n",
      "\u001b[31mBatch 287: loss = 2.1910, acc = 0.38281\u001b[0m\n",
      "\u001b[31mBatch 288: loss = 2.1738, acc = 0.37793\u001b[0m\n",
      "\u001b[31mBatch 289: loss = 2.1482, acc = 0.37988\u001b[0m\n",
      "\u001b[31mBatch 290: loss = 2.1157, acc = 0.40039\u001b[0m\n",
      "\u001b[31mBatch 291: loss = 2.2313, acc = 0.35645\u001b[0m\n",
      "\u001b[31mBatch 292: loss = 2.1905, acc = 0.37207\u001b[0m\n",
      "\u001b[31mBatch 293: loss = 2.1553, acc = 0.37012\u001b[0m\n",
      "\u001b[31mBatch 294: loss = 2.2340, acc = 0.36328\u001b[0m\n",
      "\u001b[31mBatch 295: loss = 2.2908, acc = 0.35645\u001b[0m\n",
      "\u001b[31mBatch 296: loss = 2.2380, acc = 0.35938\u001b[0m\n",
      "\u001b[31mBatch 297: loss = 2.1429, acc = 0.39551\u001b[0m\n",
      "\u001b[31mBatch 298: loss = 2.2971, acc = 0.35254\u001b[0m\n",
      "\u001b[31mBatch 299: loss = 2.2591, acc = 0.35156\u001b[0m\n",
      "\u001b[31mBatch 300: loss = 2.2500, acc = 0.35254\u001b[0m\n",
      "\u001b[31mBatch 301: loss = 2.1303, acc = 0.37598\u001b[0m\n",
      "\u001b[31mBatch 302: loss = 2.2246, acc = 0.36719\u001b[0m\n",
      "\u001b[31mBatch 303: loss = 2.1648, acc = 0.38281\u001b[0m\n",
      "\u001b[31mBatch 304: loss = 2.1716, acc = 0.38184\u001b[0m\n",
      "\u001b[31mBatch 305: loss = 2.1611, acc = 0.37988\u001b[0m\n",
      "\u001b[31mBatch 306: loss = 2.1565, acc = 0.36523\u001b[0m\n",
      "\u001b[31mBatch 307: loss = 2.1797, acc = 0.37695\u001b[0m\n",
      "\u001b[31mBatch 308: loss = 2.1914, acc = 0.37207\u001b[0m\n",
      "\u001b[31mBatch 309: loss = 2.1821, acc = 0.38281\u001b[0m\n",
      "\u001b[31mBatch 310: loss = 2.2589, acc = 0.35547\u001b[0m\n",
      "\u001b[31mBatch 311: loss = 2.1898, acc = 0.37988\u001b[0m\n",
      "\u001b[31mBatch 312: loss = 2.1823, acc = 0.37109\u001b[0m\n",
      "\u001b[31mBatch 313: loss = 2.1463, acc = 0.38086\u001b[0m\n",
      "\u001b[31mBatch 314: loss = 2.2129, acc = 0.36133\u001b[0m\n",
      "\u001b[31mBatch 315: loss = 2.3167, acc = 0.35156\u001b[0m\n",
      "\u001b[31mBatch 316: loss = 2.1826, acc = 0.37402\u001b[0m\n",
      "\u001b[31mBatch 317: loss = 2.1774, acc = 0.39453\u001b[0m\n",
      "\u001b[31mBatch 318: loss = 2.1772, acc = 0.37598\u001b[0m\n",
      "\u001b[31mBatch 319: loss = 2.0835, acc = 0.39746\u001b[0m\n",
      "\u001b[31mBatch 320: loss = 2.2118, acc = 0.37793\u001b[0m\n",
      "\u001b[31mBatch 321: loss = 2.3403, acc = 0.38965\u001b[0m\n",
      "\u001b[31mBatch 322: loss = 2.2005, acc = 0.38281\u001b[0m\n",
      "\u001b[31mBatch 323: loss = 2.2005, acc = 0.36719\u001b[0m\n",
      "\u001b[31mBatch 324: loss = 2.2017, acc = 0.38379\u001b[0m\n",
      "\u001b[31mBatch 325: loss = 2.1142, acc = 0.39453\u001b[0m\n",
      "\u001b[31mBatch 326: loss = 2.2193, acc = 0.34570\u001b[0m\n",
      "\u001b[31mBatch 327: loss = 2.1732, acc = 0.39648\u001b[0m\n",
      "\u001b[31mBatch 328: loss = 2.2318, acc = 0.36035\u001b[0m\n",
      "\u001b[31mBatch 329: loss = 2.1383, acc = 0.37695\u001b[0m\n",
      "\u001b[31mBatch 330: loss = 2.1393, acc = 0.37891\u001b[0m\n",
      "\u001b[31mBatch 331: loss = 2.2360, acc = 0.34863\u001b[0m\n",
      "\u001b[31mBatch 332: loss = 2.1790, acc = 0.36719\u001b[0m\n",
      "\u001b[31mBatch 333: loss = 2.1455, acc = 0.36230\u001b[0m\n",
      "\u001b[31mBatch 334: loss = 2.1929, acc = 0.36230\u001b[0m\n",
      "\u001b[31mBatch 335: loss = 2.1261, acc = 0.38086\u001b[0m\n",
      "\u001b[31mBatch 336: loss = 2.2011, acc = 0.38574\u001b[0m\n",
      "\u001b[31mBatch 337: loss = 2.3954, acc = 0.37500\u001b[0m\n",
      "\u001b[31mBatch 338: loss = 2.1985, acc = 0.39355\u001b[0m\n",
      "\u001b[31mBatch 339: loss = 2.1757, acc = 0.37012\u001b[0m\n",
      "\u001b[31mBatch 340: loss = 2.6315, acc = 0.35742\u001b[0m\n",
      "\u001b[31mBatch 341: loss = 2.3344, acc = 0.35059\u001b[0m\n",
      "\u001b[31mBatch 342: loss = 2.2697, acc = 0.38477\u001b[0m\n",
      "\u001b[31mBatch 343: loss = 2.1957, acc = 0.37695\u001b[0m\n",
      "\u001b[31mBatch 344: loss = 2.1956, acc = 0.37500\u001b[0m\n",
      "\u001b[31mBatch 345: loss = 2.0968, acc = 0.39844\u001b[0m\n",
      "\u001b[31mBatch 346: loss = 2.1135, acc = 0.40332\u001b[0m\n",
      "\u001b[31mBatch 347: loss = 2.1847, acc = 0.39844\u001b[0m\n",
      "\u001b[31mBatch 348: loss = 2.3286, acc = 0.39160\u001b[0m\n",
      "\u001b[31mBatch 349: loss = 2.2017, acc = 0.37305\u001b[0m\n",
      "\u001b[31mBatch 350: loss = 2.1913, acc = 0.35840\u001b[0m\n",
      "\u001b[31mBatch 351: loss = 2.1314, acc = 0.38867\u001b[0m\n",
      "\u001b[31mBatch 352: loss = 2.0785, acc = 0.40527\u001b[0m\n",
      "\u001b[31mBatch 353: loss = 2.1288, acc = 0.38965\u001b[0m\n",
      "\u001b[31mBatch 354: loss = 2.1150, acc = 0.41309\u001b[0m\n",
      "\u001b[31mBatch 355: loss = 2.1864, acc = 0.35840\u001b[0m\n",
      "\u001b[31mBatch 356: loss = 2.1248, acc = 0.39844\u001b[0m\n",
      "\u001b[31mBatch 357: loss = 2.0650, acc = 0.41211\u001b[0m\n",
      "\u001b[31mBatch 358: loss = 2.1895, acc = 0.38477\u001b[0m\n",
      "\u001b[31mBatch 359: loss = 2.1155, acc = 0.40332\u001b[0m\n",
      "\u001b[31mBatch 360: loss = 2.1352, acc = 0.37598\u001b[0m\n",
      "\u001b[31mBatch 361: loss = 2.1567, acc = 0.37891\u001b[0m\n",
      "\u001b[31mBatch 362: loss = 2.0285, acc = 0.41113\u001b[0m\n",
      "\u001b[31mBatch 363: loss = 2.0398, acc = 0.40234\u001b[0m\n",
      "\u001b[31mBatch 364: loss = 2.1596, acc = 0.37891\u001b[0m\n",
      "\u001b[31mBatch 365: loss = 2.0801, acc = 0.40234\u001b[0m\n",
      "\u001b[31mBatch 366: loss = 2.0788, acc = 0.39746\u001b[0m\n",
      "\u001b[31mBatch 367: loss = 2.0994, acc = 0.38770\u001b[0m\n",
      "\u001b[31mBatch 368: loss = 2.1303, acc = 0.37793\u001b[0m\n",
      "\u001b[31mBatch 369: loss = 2.2099, acc = 0.35938\u001b[0m\n",
      "\u001b[31mBatch 370: loss = 2.0994, acc = 0.38867\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBatch 371: loss = 1.9771, acc = 0.43750\u001b[0m\n",
      "\u001b[31mBatch 372: loss = 2.1215, acc = 0.40137\u001b[0m\n",
      "\u001b[31mBatch 373: loss = 2.0347, acc = 0.42871\u001b[0m\n",
      "\u001b[31mBatch 374: loss = 2.1547, acc = 0.37305\u001b[0m\n",
      "\u001b[31mBatch 375: loss = 2.1239, acc = 0.38672\u001b[0m\n",
      "\u001b[31mBatch 376: loss = 2.1350, acc = 0.38770\u001b[0m\n",
      "\u001b[31mBatch 377: loss = 2.1635, acc = 0.38086\u001b[0m\n",
      "\u001b[31mBatch 378: loss = 2.0774, acc = 0.41016\u001b[0m\n",
      "\u001b[31mBatch 379: loss = 2.1139, acc = 0.41113\u001b[0m\n",
      "\u001b[31mBatch 380: loss = 2.1575, acc = 0.37891\u001b[0m\n",
      "\u001b[31mBatch 381: loss = 2.1538, acc = 0.38379\u001b[0m\n",
      "\u001b[31mBatch 382: loss = 2.1042, acc = 0.39355\u001b[0m\n",
      "\u001b[31mBatch 383: loss = 2.1218, acc = 0.38184\u001b[0m\n",
      "\u001b[31mBatch 384: loss = 2.1437, acc = 0.38574\u001b[0m\n",
      "\u001b[31mBatch 385: loss = 2.1335, acc = 0.38477\u001b[0m\n",
      "\u001b[31mBatch 386: loss = 2.2512, acc = 0.37207\u001b[0m\n",
      "\u001b[31mBatch 387: loss = 2.0765, acc = 0.40137\u001b[0m\n",
      "\u001b[31mBatch 388: loss = 2.0371, acc = 0.41504\u001b[0m\n",
      "\u001b[31mBatch 389: loss = 2.0416, acc = 0.41895\u001b[0m\n",
      "\u001b[31mBatch 390: loss = 2.1350, acc = 0.39258\u001b[0m\n",
      "\u001b[31mBatch 391: loss = 2.0403, acc = 0.42480\u001b[0m\n",
      "\u001b[31mBatch 392: loss = 2.0762, acc = 0.40430\u001b[0m\n",
      "\u001b[31mBatch 393: loss = 2.0751, acc = 0.41797\u001b[0m\n",
      "\u001b[31mBatch 394: loss = 2.0878, acc = 0.40527\u001b[0m\n",
      "\u001b[31mBatch 395: loss = 2.0408, acc = 0.42090\u001b[0m\n",
      "\u001b[31mBatch 396: loss = 2.0039, acc = 0.42285\u001b[0m\n",
      "\u001b[31mBatch 397: loss = 2.0628, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 398: loss = 2.0940, acc = 0.40332\u001b[0m\n",
      "\u001b[31mBatch 399: loss = 2.1418, acc = 0.36816\u001b[0m\n",
      "\u001b[31mBatch 400: loss = 2.1137, acc = 0.40234\u001b[0m\n",
      "\u001b[31mBatch 401: loss = 2.0855, acc = 0.39355\u001b[0m\n",
      "\u001b[31mBatch 402: loss = 2.1148, acc = 0.39160\u001b[0m\n",
      "\u001b[31mBatch 403: loss = 2.0743, acc = 0.38672\u001b[0m\n",
      "\u001b[31mBatch 404: loss = 2.0432, acc = 0.41992\u001b[0m\n",
      "\u001b[31mBatch 405: loss = 2.0513, acc = 0.40039\u001b[0m\n",
      "\u001b[31mBatch 406: loss = 2.0219, acc = 0.42090\u001b[0m\n",
      "\u001b[31mBatch 407: loss = 2.0423, acc = 0.42480\u001b[0m\n",
      "\u001b[31mBatch 408: loss = 2.0644, acc = 0.41309\u001b[0m\n",
      "\u001b[31mBatch 409: loss = 2.0976, acc = 0.39160\u001b[0m\n",
      "\u001b[31mBatch 410: loss = 2.0631, acc = 0.41016\u001b[0m\n",
      "\u001b[31mBatch 411: loss = 2.0497, acc = 0.41016\u001b[0m\n",
      "\u001b[31mBatch 412: loss = 2.0887, acc = 0.41797\u001b[0m\n",
      "\u001b[31mBatch 413: loss = 2.1630, acc = 0.38184\u001b[0m\n",
      "\u001b[31mBatch 414: loss = 2.0248, acc = 0.40234\u001b[0m\n",
      "\u001b[31mBatch 415: loss = 2.0972, acc = 0.40234\u001b[0m\n",
      "\u001b[31mBatch 416: loss = 2.0256, acc = 0.41797\u001b[0m\n",
      "\u001b[31mBatch 417: loss = 2.0155, acc = 0.40820\u001b[0m\n",
      "\u001b[31mBatch 418: loss = 2.1061, acc = 0.39062\u001b[0m\n",
      "\u001b[31mBatch 419: loss = 2.0738, acc = 0.40625\u001b[0m\n",
      "\u001b[31mBatch 420: loss = 2.0936, acc = 0.39648\u001b[0m\n",
      "\u001b[31mBatch 421: loss = 2.0903, acc = 0.40625\u001b[0m\n",
      "\u001b[31mBatch 422: loss = 2.0529, acc = 0.41113\u001b[0m\n",
      "\u001b[31mBatch 423: loss = 2.0035, acc = 0.39746\u001b[0m\n",
      "\u001b[31mBatch 424: loss = 2.1052, acc = 0.39062\u001b[0m\n",
      "\u001b[31mBatch 425: loss = 1.9332, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 426: loss = 2.1028, acc = 0.39258\u001b[0m\n",
      "\u001b[31mBatch 427: loss = 2.0642, acc = 0.40723\u001b[0m\n",
      "\u001b[31mBatch 428: loss = 2.1396, acc = 0.40430\u001b[0m\n",
      "\u001b[31mBatch 429: loss = 2.0924, acc = 0.40820\u001b[0m\n",
      "\u001b[31mBatch 430: loss = 2.0249, acc = 0.39746\u001b[0m\n",
      "\u001b[31mBatch 431: loss = 2.1084, acc = 0.39258\u001b[0m\n",
      "\u001b[31mBatch 432: loss = 2.0239, acc = 0.39258\u001b[0m\n",
      "\u001b[31mBatch 433: loss = 1.9949, acc = 0.41895\u001b[0m\n",
      "\u001b[31mBatch 434: loss = 2.0197, acc = 0.41992\u001b[0m\n",
      "\u001b[31mBatch 435: loss = 2.1554, acc = 0.39160\u001b[0m\n",
      "\u001b[31mBatch 436: loss = 2.1047, acc = 0.39355\u001b[0m\n",
      "\u001b[31mBatch 437: loss = 2.0100, acc = 0.40918\u001b[0m\n",
      "\u001b[31mBatch 438: loss = 2.0014, acc = 0.41895\u001b[0m\n",
      "\u001b[31mBatch 439: loss = 2.1225, acc = 0.38184\u001b[0m\n",
      "\u001b[31mBatch 440: loss = 2.1004, acc = 0.39941\u001b[0m\n",
      "\u001b[31mBatch 441: loss = 2.0437, acc = 0.40820\u001b[0m\n",
      "\u001b[31mBatch 442: loss = 2.0661, acc = 0.39844\u001b[0m\n",
      "\u001b[31mBatch 443: loss = 2.0813, acc = 0.40039\u001b[0m\n",
      "\u001b[31mBatch 444: loss = 2.0298, acc = 0.42578\u001b[0m\n",
      "\u001b[31mBatch 445: loss = 1.9977, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 446: loss = 1.9251, acc = 0.43066\u001b[0m\n",
      "\u001b[31mBatch 447: loss = 1.9945, acc = 0.41113\u001b[0m\n",
      "\u001b[31mBatch 448: loss = 2.0428, acc = 0.40137\u001b[0m\n",
      "\u001b[31mBatch 449: loss = 1.9771, acc = 0.40918\u001b[0m\n",
      "\u001b[31mBatch 450: loss = 2.0150, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 451: loss = 2.0437, acc = 0.42090\u001b[0m\n",
      "\u001b[31mBatch 452: loss = 2.0839, acc = 0.39258\u001b[0m\n",
      "\u001b[31mBatch 453: loss = 2.0782, acc = 0.43262\u001b[0m\n",
      "\u001b[31mBatch 454: loss = 1.9813, acc = 0.44238\u001b[0m\n",
      "\u001b[31mBatch 455: loss = 2.0638, acc = 0.42871\u001b[0m\n",
      "\u001b[31mBatch 456: loss = 2.0336, acc = 0.42676\u001b[0m\n",
      "\u001b[31mBatch 457: loss = 1.9892, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 458: loss = 1.9645, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 459: loss = 1.9558, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 460: loss = 2.0557, acc = 0.41797\u001b[0m\n",
      "\u001b[31mBatch 461: loss = 1.9839, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 462: loss = 1.8943, acc = 0.44336\u001b[0m\n",
      "\u001b[31mBatch 463: loss = 1.9828, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 464: loss = 2.0307, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 465: loss = 2.0079, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 466: loss = 1.9727, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 467: loss = 2.0571, acc = 0.41895\u001b[0m\n",
      "\u001b[31mBatch 468: loss = 2.0080, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 469: loss = 2.0108, acc = 0.40820\u001b[0m\n",
      "\u001b[31mBatch 470: loss = 1.9341, acc = 0.45117\u001b[0m\n",
      "\u001b[31mBatch 471: loss = 2.0206, acc = 0.43262\u001b[0m\n",
      "\u001b[31mBatch 472: loss = 1.9529, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 473: loss = 1.9837, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 474: loss = 1.9800, acc = 0.43457\u001b[0m\n",
      "\u001b[31mBatch 475: loss = 1.9029, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 476: loss = 2.0654, acc = 0.41504\u001b[0m\n",
      "\u001b[31mBatch 477: loss = 1.9618, acc = 0.42480\u001b[0m\n",
      "\u001b[31mBatch 478: loss = 1.9726, acc = 0.43359\u001b[0m\n",
      "\u001b[31mBatch 479: loss = 2.0284, acc = 0.41309\u001b[0m\n",
      "\u001b[31mBatch 480: loss = 1.9089, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 481: loss = 1.9687, acc = 0.42773\u001b[0m\n",
      "\u001b[31mBatch 482: loss = 1.9672, acc = 0.41992\u001b[0m\n",
      "\u001b[31mBatch 483: loss = 1.9993, acc = 0.41699\u001b[0m\n",
      "\u001b[31mBatch 484: loss = 1.9960, acc = 0.42480\u001b[0m\n",
      "\u001b[31mBatch 485: loss = 1.9762, acc = 0.41797\u001b[0m\n",
      "\u001b[31mBatch 486: loss = 1.9242, acc = 0.44434\u001b[0m\n",
      "\u001b[31mBatch 487: loss = 2.1074, acc = 0.39844\u001b[0m\n",
      "\u001b[31mBatch 488: loss = 1.9253, acc = 0.44336\u001b[0m\n",
      "\u001b[31mBatch 489: loss = 1.9436, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 490: loss = 1.9053, acc = 0.43359\u001b[0m\n",
      "\u001b[31mBatch 491: loss = 1.9262, acc = 0.45312\u001b[0m\n",
      "\u001b[31mBatch 492: loss = 1.9554, acc = 0.43262\u001b[0m\n",
      "\u001b[31mBatch 493: loss = 1.9742, acc = 0.45410\u001b[0m\n",
      "\u001b[31mBatch 494: loss = 1.9153, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 495: loss = 1.9540, acc = 0.45410\u001b[0m\n",
      "\u001b[31mBatch 496: loss = 1.9344, acc = 0.42676\u001b[0m\n",
      "\u001b[31mBatch 497: loss = 2.0262, acc = 0.39355\u001b[0m\n",
      "\u001b[31mBatch 498: loss = 1.8923, acc = 0.44043\u001b[0m\n",
      "\u001b[31mBatch 499: loss = 1.8950, acc = 0.42480\u001b[0m\n",
      "\u001b[31mBatch 500: loss = 1.8875, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 501: loss = 1.9849, acc = 0.40527\u001b[0m\n",
      "\u001b[31mBatch 502: loss = 1.9410, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 503: loss = 1.9956, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 504: loss = 1.9152, acc = 0.43457\u001b[0m\n",
      "\u001b[31mBatch 505: loss = 1.9997, acc = 0.41602\u001b[0m\n",
      "\u001b[31mBatch 506: loss = 1.9034, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 507: loss = 1.9890, acc = 0.41211\u001b[0m\n",
      "\u001b[31mBatch 508: loss = 1.9571, acc = 0.40820\u001b[0m\n",
      "\u001b[31mBatch 509: loss = 1.9492, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 510: loss = 1.9409, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 511: loss = 1.8993, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 512: loss = 1.9885, acc = 0.41406\u001b[0m\n",
      "\u001b[31mBatch 513: loss = 2.0014, acc = 0.41602\u001b[0m\n",
      "\u001b[31mBatch 514: loss = 1.9409, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 515: loss = 2.0062, acc = 0.40137\u001b[0m\n",
      "\u001b[31mBatch 516: loss = 1.9285, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 517: loss = 1.9530, acc = 0.42188\u001b[0m\n",
      "\u001b[31mBatch 518: loss = 1.9913, acc = 0.42090\u001b[0m\n",
      "\u001b[31mBatch 519: loss = 1.9176, acc = 0.44336\u001b[0m\n",
      "\u001b[31mBatch 520: loss = 1.9247, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 521: loss = 1.9918, acc = 0.42383\u001b[0m\n",
      "\u001b[31mBatch 522: loss = 1.9368, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 523: loss = 2.0139, acc = 0.42383\u001b[0m\n",
      "\u001b[31mBatch 524: loss = 1.9518, acc = 0.43359\u001b[0m\n",
      "\u001b[31mBatch 525: loss = 1.9215, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 526: loss = 1.8931, acc = 0.45312\u001b[0m\n",
      "\u001b[31mBatch 527: loss = 1.9183, acc = 0.42773\u001b[0m\n",
      "\u001b[31mBatch 528: loss = 1.8712, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 529: loss = 1.8971, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 530: loss = 1.9143, acc = 0.43848\u001b[0m\n",
      "\u001b[31mBatch 531: loss = 1.9684, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 532: loss = 1.8923, acc = 0.45215\u001b[0m\n",
      "\u001b[31mBatch 533: loss = 1.9218, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 534: loss = 1.8974, acc = 0.43750\u001b[0m\n",
      "\u001b[31mBatch 535: loss = 1.9367, acc = 0.41699\u001b[0m\n",
      "\u001b[31mBatch 536: loss = 1.9470, acc = 0.42383\u001b[0m\n",
      "\u001b[31mBatch 537: loss = 1.8543, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 538: loss = 2.0112, acc = 0.41602\u001b[0m\n",
      "\u001b[31mBatch 539: loss = 1.9163, acc = 0.42676\u001b[0m\n",
      "\u001b[31mBatch 540: loss = 1.9164, acc = 0.42578\u001b[0m\n",
      "\u001b[31mBatch 541: loss = 1.9090, acc = 0.45215\u001b[0m\n",
      "\u001b[31mBatch 542: loss = 1.9519, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 543: loss = 1.9189, acc = 0.43848\u001b[0m\n",
      "\u001b[31mBatch 544: loss = 1.9186, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 545: loss = 1.8612, acc = 0.44434\u001b[0m\n",
      "\u001b[31mBatch 546: loss = 1.8648, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 547: loss = 2.0474, acc = 0.43359\u001b[0m\n",
      "\u001b[31mBatch 548: loss = 1.9941, acc = 0.44238\u001b[0m\n",
      "\u001b[31mBatch 549: loss = 1.8807, acc = 0.44434\u001b[0m\n",
      "\u001b[31mBatch 550: loss = 1.9110, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 551: loss = 1.8960, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 552: loss = 1.8396, acc = 0.46875\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBatch 553: loss = 1.9270, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 554: loss = 1.9029, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 555: loss = 1.9506, acc = 0.43359\u001b[0m\n",
      "\u001b[31mBatch 556: loss = 1.9567, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 557: loss = 1.8270, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 558: loss = 1.8273, acc = 0.45215\u001b[0m\n",
      "\u001b[31mBatch 559: loss = 1.9470, acc = 0.43750\u001b[0m\n",
      "\u001b[31mBatch 560: loss = 1.8604, acc = 0.44336\u001b[0m\n",
      "\u001b[31mBatch 561: loss = 1.9725, acc = 0.42383\u001b[0m\n",
      "\u001b[31mBatch 562: loss = 1.9562, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 563: loss = 1.8906, acc = 0.44727\u001b[0m\n",
      "\u001b[31mBatch 564: loss = 1.8509, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 565: loss = 1.9720, acc = 0.41699\u001b[0m\n",
      "\u001b[31mBatch 566: loss = 1.9447, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 567: loss = 1.8517, acc = 0.45215\u001b[0m\n",
      "\u001b[31mBatch 568: loss = 1.9443, acc = 0.44043\u001b[0m\n",
      "\u001b[31mBatch 569: loss = 1.9875, acc = 0.41113\u001b[0m\n",
      "\u001b[31mBatch 570: loss = 1.9377, acc = 0.42480\u001b[0m\n",
      "\u001b[31mBatch 571: loss = 1.9097, acc = 0.42285\u001b[0m\n",
      "\u001b[31mBatch 572: loss = 1.8421, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 573: loss = 1.8472, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 574: loss = 1.9361, acc = 0.41797\u001b[0m\n",
      "\u001b[31mBatch 575: loss = 1.8128, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 576: loss = 1.9525, acc = 0.41895\u001b[0m\n",
      "\u001b[31mBatch 577: loss = 1.8665, acc = 0.45215\u001b[0m\n",
      "\u001b[31mBatch 578: loss = 1.8711, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 579: loss = 1.8297, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 580: loss = 1.8744, acc = 0.43848\u001b[0m\n",
      "\u001b[31mBatch 581: loss = 1.9082, acc = 0.42871\u001b[0m\n",
      "\u001b[31mBatch 582: loss = 1.9642, acc = 0.41992\u001b[0m\n",
      "\u001b[31mBatch 583: loss = 1.8588, acc = 0.43848\u001b[0m\n",
      "\u001b[31mBatch 584: loss = 1.8437, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 585: loss = 1.9432, acc = 0.42383\u001b[0m\n",
      "\u001b[31mBatch 586: loss = 1.9302, acc = 0.41992\u001b[0m\n",
      "\u001b[31mBatch 587: loss = 1.8240, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 588: loss = 1.7889, acc = 0.48535\u001b[0m\n",
      "\u001b[31mBatch 589: loss = 2.0658, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 590: loss = 2.1216, acc = 0.39844\u001b[0m\n",
      "\u001b[31mBatch 591: loss = 2.0253, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 592: loss = 2.0155, acc = 0.41699\u001b[0m\n",
      "\u001b[31mBatch 593: loss = 2.0322, acc = 0.39160\u001b[0m\n",
      "\u001b[31mBatch 594: loss = 2.0840, acc = 0.41113\u001b[0m\n",
      "\u001b[31mBatch 595: loss = 1.7802, acc = 0.49121\u001b[0m\n",
      "\u001b[31mBatch 596: loss = 1.8579, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 597: loss = 1.8802, acc = 0.46387\u001b[0m\n",
      "\u001b[31mBatch 598: loss = 1.9030, acc = 0.43262\u001b[0m\n",
      "\u001b[31mBatch 599: loss = 1.8838, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 600: loss = 1.8546, acc = 0.45996\u001b[0m\n",
      "\u001b[31mBatch 601: loss = 1.9888, acc = 0.42773\u001b[0m\n",
      "\u001b[31mBatch 602: loss = 1.8549, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 603: loss = 1.9728, acc = 0.43262\u001b[0m\n",
      "\u001b[31mBatch 604: loss = 1.8985, acc = 0.44336\u001b[0m\n",
      "\u001b[31mBatch 605: loss = 1.9070, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 606: loss = 2.0633, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 607: loss = 1.9133, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 608: loss = 1.9303, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 609: loss = 1.8697, acc = 0.47168\u001b[0m\n",
      "\u001b[31mBatch 610: loss = 1.9014, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 611: loss = 1.9932, acc = 0.41699\u001b[0m\n",
      "\u001b[31mBatch 612: loss = 1.8760, acc = 0.45117\u001b[0m\n",
      "\u001b[31mBatch 613: loss = 1.8675, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 614: loss = 1.9480, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 615: loss = 2.0147, acc = 0.42676\u001b[0m\n",
      "\u001b[31mBatch 616: loss = 1.9895, acc = 0.42578\u001b[0m\n",
      "\u001b[31mBatch 617: loss = 1.8384, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 618: loss = 1.9559, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 619: loss = 1.9555, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 620: loss = 1.9320, acc = 0.43359\u001b[0m\n",
      "\u001b[31mBatch 621: loss = 1.8783, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 622: loss = 1.9287, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 623: loss = 1.8654, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 624: loss = 1.8993, acc = 0.43555\u001b[0m\n",
      "\u001b[31mBatch 625: loss = 1.8956, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 626: loss = 1.9681, acc = 0.43262\u001b[0m\n",
      "\u001b[31mBatch 627: loss = 1.9257, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 628: loss = 1.9873, acc = 0.42773\u001b[0m\n",
      "\u001b[31mBatch 629: loss = 1.9049, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 630: loss = 1.8005, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 631: loss = 1.8491, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 632: loss = 1.8251, acc = 0.46680\u001b[0m\n",
      "\u001b[31mBatch 633: loss = 1.7887, acc = 0.45898\u001b[0m\n",
      "\u001b[31mBatch 634: loss = 1.8384, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 635: loss = 1.9031, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 636: loss = 1.8622, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 637: loss = 1.8038, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 638: loss = 1.8454, acc = 0.45996\u001b[0m\n",
      "\u001b[31mBatch 639: loss = 1.8515, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 640: loss = 1.8281, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 641: loss = 1.8284, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 642: loss = 1.7658, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 643: loss = 1.8431, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 644: loss = 1.8529, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 645: loss = 1.8842, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 646: loss = 1.9160, acc = 0.43750\u001b[0m\n",
      "\u001b[31mBatch 647: loss = 1.8217, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 648: loss = 1.8539, acc = 0.46387\u001b[0m\n",
      "\u001b[31mBatch 649: loss = 1.8557, acc = 0.45898\u001b[0m\n",
      "\u001b[31mBatch 650: loss = 1.8589, acc = 0.45312\u001b[0m\n",
      "\u001b[31mBatch 651: loss = 1.9251, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 652: loss = 1.8603, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 653: loss = 1.8758, acc = 0.42969\u001b[0m\n",
      "\u001b[31mBatch 654: loss = 1.8554, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 655: loss = 1.8313, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 656: loss = 1.8274, acc = 0.43750\u001b[0m\n",
      "\u001b[31mBatch 657: loss = 1.9304, acc = 0.45703\u001b[0m\n",
      "\u001b[31mBatch 658: loss = 1.8374, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 659: loss = 1.7801, acc = 0.48926\u001b[0m\n",
      "\u001b[31mBatch 660: loss = 1.8989, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 661: loss = 1.8346, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 662: loss = 1.8184, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 663: loss = 1.8314, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 664: loss = 1.8538, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 665: loss = 1.8750, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 666: loss = 1.7845, acc = 0.47461\u001b[0m\n",
      "\u001b[31mBatch 667: loss = 1.7837, acc = 0.45898\u001b[0m\n",
      "\u001b[31mBatch 668: loss = 1.7884, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 669: loss = 1.8454, acc = 0.46484\u001b[0m\n",
      "\u001b[31mBatch 670: loss = 1.8266, acc = 0.45898\u001b[0m\n",
      "\u001b[31mBatch 671: loss = 1.8809, acc = 0.44727\u001b[0m\n",
      "\u001b[31mBatch 672: loss = 1.7943, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 673: loss = 1.8945, acc = 0.45117\u001b[0m\n",
      "\u001b[31mBatch 674: loss = 1.8516, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 675: loss = 1.8428, acc = 0.44531\u001b[0m\n",
      "\u001b[31mBatch 676: loss = 1.8639, acc = 0.43848\u001b[0m\n",
      "\u001b[31mBatch 677: loss = 1.8252, acc = 0.43164\u001b[0m\n",
      "\u001b[31mBatch 678: loss = 1.8216, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 679: loss = 1.8285, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 680: loss = 1.8562, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 681: loss = 1.8091, acc = 0.48145\u001b[0m\n",
      "\u001b[31mBatch 682: loss = 1.8086, acc = 0.47754\u001b[0m\n",
      "\u001b[31mBatch 683: loss = 1.8198, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 684: loss = 1.8890, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 685: loss = 1.8230, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 686: loss = 1.7684, acc = 0.47852\u001b[0m\n",
      "\u001b[31mBatch 687: loss = 1.8971, acc = 0.45117\u001b[0m\n",
      "\u001b[31mBatch 688: loss = 1.7427, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 689: loss = 1.8550, acc = 0.45410\u001b[0m\n",
      "\u001b[31mBatch 690: loss = 1.8250, acc = 0.45410\u001b[0m\n",
      "\u001b[31mBatch 691: loss = 1.8076, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 692: loss = 1.8553, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 693: loss = 1.8595, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 694: loss = 1.8590, acc = 0.45996\u001b[0m\n",
      "\u001b[31mBatch 695: loss = 1.8815, acc = 0.44434\u001b[0m\n",
      "\u001b[31mBatch 696: loss = 1.9662, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 697: loss = 1.7677, acc = 0.48242\u001b[0m\n",
      "\u001b[31mBatch 698: loss = 1.8102, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 699: loss = 1.8236, acc = 0.46680\u001b[0m\n",
      "\u001b[31mBatch 700: loss = 1.7684, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 701: loss = 1.8148, acc = 0.48145\u001b[0m\n",
      "\u001b[31mBatch 702: loss = 1.8954, acc = 0.43750\u001b[0m\n",
      "\u001b[31mBatch 703: loss = 1.8072, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 704: loss = 1.8588, acc = 0.45410\u001b[0m\n",
      "\u001b[31mBatch 705: loss = 1.7806, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 706: loss = 1.8248, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 707: loss = 1.8147, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 708: loss = 1.8456, acc = 0.45117\u001b[0m\n",
      "\u001b[31mBatch 709: loss = 1.8907, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 710: loss = 1.7840, acc = 0.49414\u001b[0m\n",
      "\u001b[31mBatch 711: loss = 1.7837, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 712: loss = 1.8799, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 713: loss = 1.8090, acc = 0.47656\u001b[0m\n",
      "\u001b[31mBatch 714: loss = 1.8644, acc = 0.45703\u001b[0m\n",
      "\u001b[31mBatch 715: loss = 1.8205, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 716: loss = 1.8607, acc = 0.46875\u001b[0m\n",
      "\u001b[31mBatch 717: loss = 1.7394, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 718: loss = 1.7897, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 719: loss = 1.7790, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 720: loss = 1.7949, acc = 0.47949\u001b[0m\n",
      "\u001b[31mBatch 721: loss = 1.8288, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 722: loss = 1.7265, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 723: loss = 1.6682, acc = 0.51367\u001b[0m\n",
      "\u001b[31mBatch 724: loss = 1.8691, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 725: loss = 1.7562, acc = 0.47852\u001b[0m\n",
      "\u001b[31mBatch 726: loss = 1.7754, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 727: loss = 1.7780, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 728: loss = 1.8018, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 729: loss = 1.7200, acc = 0.49316\u001b[0m\n",
      "\u001b[31mBatch 730: loss = 1.7846, acc = 0.46680\u001b[0m\n",
      "\u001b[31mBatch 731: loss = 1.8113, acc = 0.47461\u001b[0m\n",
      "\u001b[31mBatch 732: loss = 1.7755, acc = 0.47559\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBatch 733: loss = 1.7662, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 734: loss = 1.8110, acc = 0.49121\u001b[0m\n",
      "\u001b[31mBatch 735: loss = 1.8874, acc = 0.44434\u001b[0m\n",
      "\u001b[31mBatch 736: loss = 1.8992, acc = 0.43945\u001b[0m\n",
      "\u001b[31mBatch 737: loss = 1.7888, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 738: loss = 1.7895, acc = 0.46484\u001b[0m\n",
      "\u001b[31mBatch 739: loss = 1.8390, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 740: loss = 1.8654, acc = 0.44629\u001b[0m\n",
      "\u001b[31mBatch 741: loss = 1.8551, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 742: loss = 1.8291, acc = 0.43652\u001b[0m\n",
      "\u001b[31mBatch 743: loss = 1.7723, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 744: loss = 1.8402, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 745: loss = 1.8937, acc = 0.44238\u001b[0m\n",
      "\u001b[31mBatch 746: loss = 1.9155, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 747: loss = 1.9286, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 748: loss = 1.8628, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 749: loss = 1.8188, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 750: loss = 1.9733, acc = 0.43457\u001b[0m\n",
      "\u001b[31mBatch 751: loss = 1.8658, acc = 0.47461\u001b[0m\n",
      "\u001b[31mBatch 752: loss = 1.7925, acc = 0.48145\u001b[0m\n",
      "\u001b[31mBatch 753: loss = 1.6837, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 754: loss = 1.7726, acc = 0.48145\u001b[0m\n",
      "\u001b[31mBatch 755: loss = 2.0085, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 756: loss = 1.7389, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 757: loss = 1.7414, acc = 0.48242\u001b[0m\n",
      "\u001b[31mBatch 758: loss = 1.8419, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 759: loss = 1.8041, acc = 0.49707\u001b[0m\n",
      "\u001b[31mBatch 760: loss = 1.8449, acc = 0.45117\u001b[0m\n",
      "\u001b[31mBatch 761: loss = 1.7572, acc = 0.48145\u001b[0m\n",
      "\u001b[31mBatch 762: loss = 1.7872, acc = 0.47559\u001b[0m\n",
      "\u001b[31mBatch 763: loss = 1.8656, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 764: loss = 1.8234, acc = 0.46875\u001b[0m\n",
      "\u001b[31mBatch 765: loss = 1.8143, acc = 0.48730\u001b[0m\n",
      "\u001b[31mBatch 766: loss = 1.8424, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 767: loss = 1.7599, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 768: loss = 1.9179, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 769: loss = 1.7994, acc = 0.47559\u001b[0m\n",
      "\u001b[31mBatch 770: loss = 1.7895, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 771: loss = 1.6561, acc = 0.50781\u001b[0m\n",
      "\u001b[31mBatch 772: loss = 1.7540, acc = 0.48926\u001b[0m\n",
      "\u001b[31mBatch 773: loss = 1.7940, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 774: loss = 1.7770, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 775: loss = 1.8030, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 776: loss = 1.8511, acc = 0.45898\u001b[0m\n",
      "\u001b[31mBatch 777: loss = 1.8280, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 778: loss = 1.7825, acc = 0.46484\u001b[0m\n",
      "\u001b[31mBatch 779: loss = 1.8254, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 780: loss = 1.7880, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 781: loss = 1.8021, acc = 0.45703\u001b[0m\n",
      "\u001b[31mBatch 782: loss = 1.8270, acc = 0.45703\u001b[0m\n",
      "\u001b[31mBatch 783: loss = 1.7555, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 784: loss = 1.7256, acc = 0.48340\u001b[0m\n",
      "\u001b[31mBatch 785: loss = 1.7822, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 786: loss = 1.8795, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 787: loss = 1.8128, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 788: loss = 1.7880, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 789: loss = 1.8309, acc = 0.49121\u001b[0m\n",
      "\u001b[31mBatch 790: loss = 1.9002, acc = 0.45020\u001b[0m\n",
      "\u001b[31mBatch 791: loss = 1.8667, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 792: loss = 1.9320, acc = 0.44141\u001b[0m\n",
      "\u001b[31mBatch 793: loss = 1.8703, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 794: loss = 1.8172, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 795: loss = 1.8720, acc = 0.45312\u001b[0m\n",
      "\u001b[31mBatch 796: loss = 1.7808, acc = 0.48633\u001b[0m\n",
      "\u001b[31mBatch 797: loss = 1.7651, acc = 0.49805\u001b[0m\n",
      "\u001b[31mBatch 798: loss = 1.7571, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 799: loss = 1.7711, acc = 0.48438\u001b[0m\n",
      "\u001b[31mBatch 800: loss = 1.7201, acc = 0.50684\u001b[0m\n",
      "\u001b[31mBatch 801: loss = 1.8038, acc = 0.48535\u001b[0m\n",
      "\u001b[31mBatch 802: loss = 1.7801, acc = 0.47754\u001b[0m\n",
      "\u001b[31mBatch 803: loss = 1.7829, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 804: loss = 1.7693, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 805: loss = 1.8389, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 806: loss = 1.8186, acc = 0.46680\u001b[0m\n",
      "\u001b[31mBatch 807: loss = 1.7853, acc = 0.49316\u001b[0m\n",
      "\u001b[31mBatch 808: loss = 1.6542, acc = 0.50000\u001b[0m\n",
      "\u001b[31mBatch 809: loss = 1.8034, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 810: loss = 1.7546, acc = 0.48926\u001b[0m\n",
      "\u001b[31mBatch 811: loss = 1.7467, acc = 0.48242\u001b[0m\n",
      "\u001b[31mBatch 812: loss = 1.7746, acc = 0.47559\u001b[0m\n",
      "\u001b[31mBatch 813: loss = 1.7393, acc = 0.49121\u001b[0m\n",
      "\u001b[31mBatch 814: loss = 1.6848, acc = 0.51367\u001b[0m\n",
      "\u001b[31mBatch 815: loss = 1.7381, acc = 0.48926\u001b[0m\n",
      "\u001b[31mBatch 816: loss = 1.7235, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 817: loss = 1.8196, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 818: loss = 1.6944, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 819: loss = 1.7316, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 820: loss = 1.6720, acc = 0.50879\u001b[0m\n",
      "\u001b[31mBatch 821: loss = 1.7449, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 822: loss = 1.7696, acc = 0.49316\u001b[0m\n",
      "\u001b[31mBatch 823: loss = 1.6831, acc = 0.50586\u001b[0m\n",
      "\u001b[31mBatch 824: loss = 1.8266, acc = 0.45410\u001b[0m\n",
      "\u001b[31mBatch 825: loss = 1.7206, acc = 0.49121\u001b[0m\n",
      "\u001b[31mBatch 826: loss = 1.6653, acc = 0.51758\u001b[0m\n",
      "\u001b[31mBatch 827: loss = 1.7483, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 828: loss = 1.7132, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 829: loss = 1.7469, acc = 0.47656\u001b[0m\n",
      "\u001b[31mBatch 830: loss = 1.7684, acc = 0.49805\u001b[0m\n",
      "\u001b[31mBatch 831: loss = 1.8403, acc = 0.46875\u001b[0m\n",
      "\u001b[31mBatch 832: loss = 1.6971, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 833: loss = 1.7205, acc = 0.47559\u001b[0m\n",
      "\u001b[31mBatch 834: loss = 1.6282, acc = 0.50879\u001b[0m\n",
      "\u001b[31mBatch 835: loss = 1.6969, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 836: loss = 1.8070, acc = 0.46875\u001b[0m\n",
      "\u001b[31mBatch 837: loss = 1.8269, acc = 0.48242\u001b[0m\n",
      "\u001b[31mBatch 838: loss = 1.8394, acc = 0.47266\u001b[0m\n",
      "\u001b[31mBatch 839: loss = 1.8400, acc = 0.45215\u001b[0m\n",
      "\u001b[31mBatch 840: loss = 1.7596, acc = 0.48047\u001b[0m\n",
      "\u001b[31mBatch 841: loss = 1.6946, acc = 0.50586\u001b[0m\n",
      "\u001b[31mBatch 842: loss = 1.7428, acc = 0.48730\u001b[0m\n",
      "\u001b[31mBatch 843: loss = 1.7545, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 844: loss = 1.7267, acc = 0.50488\u001b[0m\n",
      "\u001b[31mBatch 845: loss = 1.8271, acc = 0.47461\u001b[0m\n",
      "\u001b[31mBatch 846: loss = 1.6993, acc = 0.49805\u001b[0m\n",
      "\u001b[31mBatch 847: loss = 1.7220, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 848: loss = 1.7152, acc = 0.48730\u001b[0m\n",
      "\u001b[31mBatch 849: loss = 1.7955, acc = 0.47754\u001b[0m\n",
      "\u001b[31mBatch 850: loss = 1.7244, acc = 0.47852\u001b[0m\n",
      "\u001b[31mBatch 851: loss = 1.7237, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 852: loss = 1.7768, acc = 0.46289\u001b[0m\n",
      "\u001b[31mBatch 853: loss = 1.9762, acc = 0.46582\u001b[0m\n",
      "\u001b[31mBatch 854: loss = 1.7843, acc = 0.45898\u001b[0m\n",
      "\u001b[31mBatch 855: loss = 1.7482, acc = 0.48633\u001b[0m\n",
      "\u001b[31mBatch 856: loss = 1.7579, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 857: loss = 1.8253, acc = 0.46680\u001b[0m\n",
      "\u001b[31mBatch 858: loss = 1.7405, acc = 0.49902\u001b[0m\n",
      "\u001b[31mBatch 859: loss = 1.7517, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 860: loss = 1.7536, acc = 0.48926\u001b[0m\n",
      "\u001b[31mBatch 861: loss = 1.7422, acc = 0.48145\u001b[0m\n",
      "\u001b[31mBatch 862: loss = 1.7559, acc = 0.47949\u001b[0m\n",
      "\u001b[31mBatch 863: loss = 1.6678, acc = 0.50098\u001b[0m\n",
      "\u001b[31mBatch 864: loss = 1.7531, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 865: loss = 1.7746, acc = 0.48242\u001b[0m\n",
      "\u001b[31mBatch 866: loss = 1.7934, acc = 0.48047\u001b[0m\n",
      "\u001b[31mBatch 867: loss = 1.6032, acc = 0.51367\u001b[0m\n",
      "\u001b[31mBatch 868: loss = 1.8206, acc = 0.46387\u001b[0m\n",
      "\u001b[31mBatch 869: loss = 1.7924, acc = 0.48633\u001b[0m\n",
      "\u001b[31mBatch 870: loss = 1.8410, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 871: loss = 1.8375, acc = 0.44922\u001b[0m\n",
      "\u001b[31mBatch 872: loss = 1.7472, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 873: loss = 1.7677, acc = 0.49805\u001b[0m\n",
      "\u001b[31mBatch 874: loss = 1.7592, acc = 0.49805\u001b[0m\n",
      "\u001b[31mBatch 875: loss = 1.7952, acc = 0.47461\u001b[0m\n",
      "\u001b[31mBatch 876: loss = 1.7618, acc = 0.47754\u001b[0m\n",
      "\u001b[31mBatch 877: loss = 1.7070, acc = 0.49316\u001b[0m\n",
      "\u001b[31mBatch 878: loss = 1.7134, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 879: loss = 1.8175, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 880: loss = 1.7960, acc = 0.44824\u001b[0m\n",
      "\u001b[31mBatch 881: loss = 1.7225, acc = 0.49121\u001b[0m\n",
      "\u001b[31mBatch 882: loss = 1.6323, acc = 0.51270\u001b[0m\n",
      "\u001b[31mBatch 883: loss = 1.7538, acc = 0.45605\u001b[0m\n",
      "\u001b[31mBatch 884: loss = 1.7779, acc = 0.46094\u001b[0m\n",
      "\u001b[31mBatch 885: loss = 1.8614, acc = 0.46777\u001b[0m\n",
      "\u001b[31mBatch 886: loss = 1.8255, acc = 0.44727\u001b[0m\n",
      "\u001b[31mBatch 887: loss = 1.7809, acc = 0.46191\u001b[0m\n",
      "\u001b[31mBatch 888: loss = 1.8461, acc = 0.45801\u001b[0m\n",
      "\u001b[31mBatch 889: loss = 1.7825, acc = 0.48242\u001b[0m\n",
      "\u001b[31mBatch 890: loss = 1.7618, acc = 0.49609\u001b[0m\n",
      "\u001b[31mBatch 891: loss = 1.8251, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 892: loss = 1.7626, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 893: loss = 1.7115, acc = 0.47461\u001b[0m\n",
      "\u001b[31mBatch 894: loss = 1.6886, acc = 0.48535\u001b[0m\n",
      "\u001b[31mBatch 895: loss = 1.7286, acc = 0.49023\u001b[0m\n",
      "\u001b[31mBatch 896: loss = 1.7836, acc = 0.47363\u001b[0m\n",
      "\u001b[31mBatch 897: loss = 1.7307, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 898: loss = 1.7022, acc = 0.48730\u001b[0m\n",
      "\u001b[31mBatch 899: loss = 1.6721, acc = 0.51172\u001b[0m\n",
      "\u001b[31mBatch 900: loss = 1.7904, acc = 0.47461\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mBatch 901: loss = 1.7037, acc = 0.50195\u001b[0m\n",
      "\u001b[31mBatch 902: loss = 1.7251, acc = 0.51270\u001b[0m\n",
      "\u001b[31mBatch 903: loss = 1.7112, acc = 0.47949\u001b[0m\n",
      "\u001b[31mBatch 904: loss = 1.7177, acc = 0.47754\u001b[0m\n",
      "\u001b[31mBatch 905: loss = 1.8658, acc = 0.45508\u001b[0m\n",
      "\u001b[31mBatch 906: loss = 1.7263, acc = 0.48438\u001b[0m\n",
      "\u001b[31mBatch 907: loss = 1.8066, acc = 0.47656\u001b[0m\n",
      "\u001b[31mBatch 908: loss = 1.7988, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 909: loss = 1.6407, acc = 0.50000\u001b[0m\n",
      "\u001b[31mBatch 910: loss = 1.7720, acc = 0.47656\u001b[0m\n",
      "\u001b[31mBatch 911: loss = 1.7030, acc = 0.49219\u001b[0m\n",
      "\u001b[31mBatch 912: loss = 1.7897, acc = 0.47070\u001b[0m\n",
      "\u001b[31mBatch 913: loss = 1.6903, acc = 0.47852\u001b[0m\n",
      "\u001b[31mBatch 914: loss = 1.6968, acc = 0.49512\u001b[0m\n",
      "\u001b[31mBatch 915: loss = 1.7233, acc = 0.46973\u001b[0m\n",
      "\u001b[31mBatch 916: loss = 1.7381, acc = 0.48047\u001b[0m\n",
      "\u001b[31mBatch 917: loss = 1.7281, acc = 0.48730\u001b[0m\n",
      "\u001b[31mBatch 918: loss = 1.7631, acc = 0.48535\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "estimator = TensorFlow(entry_point='train.py',\n",
    "                       source_dir='char-rnn-keras',\n",
    "                       train_instance_type='ml.c4.xlarge', # Executes training in a ml.c4.xlarge instance\n",
    "                       train_instance_count=1,\n",
    "                       hyperparameters=hyperparameters,\n",
    "                       role=sagemaker.get_execution_role(),\n",
    "                       framework_version='1.13',\n",
    "                       py_version='py3',\n",
    "                       script_mode=True)\n",
    "             \n",
    "\n",
    "estimator.fit({'training': inputs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
